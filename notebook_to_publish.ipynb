{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable ecco!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've build a small addition to the ecco library (https://github.com/jalammar/ecco) using openai's api to automatically explain what the clusters found through non-negative matrix factorizations (NNMF) might have in common!\n",
    "I thought ecco was a nice library to build the addition to because this project was quite experimental, and the vizualisations of ecco makes it easy to do assess whether the interpretation/summary that the LLM is providing!\n",
    "Table of Content: \n",
    "- Short intro to ECCO\n",
    "- Description of .explain() method\n",
    "- .explain() in action!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short intro to ECCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import ecco\n",
    "lm = ecco.from_pretrained('distilbert-base-uncased', activations=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecco is a library providing interactive visualizations to some well-known large language model analysis methods.\n",
    "It has a few pretrained models - and for this project I'll be using the \"distilbert-base-uncased\" model since I can easily run inference using the model locally, but the .explain() methods works for all the models in ecco.\n",
    "Below I've provided an example of the explore method, but Jay Alammar provides more indepth examples here: https://jalammar.github.io/explaining-transformers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html lang=\"en\">\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "    var ecco_url = 'https://storage.googleapis.com/ml-intro/ecco/'\n",
       "    //var ecco_url = 'http://localhost:8000/'\n",
       "\n",
       "    if (window.ecco === undefined) window.ecco = {}\n",
       "\n",
       "    // Setup the paths of the script we'll be using\n",
       "    requirejs.config({\n",
       "        urlArgs: \"bust=\" + (new Date()).getTime(),\n",
       "        nodeRequire: require,\n",
       "        paths: {\n",
       "            d3: \"https://d3js.org/d3.v6.min\", // This is only for use in setup.html and basic.html\n",
       "            \"d3-array\": \"https://d3js.org/d3-array.v2.min\",\n",
       "            jquery: \"https://code.jquery.com/jquery-3.5.1.min\",\n",
       "            ecco: ecco_url + 'js/0.0.6/ecco-bundle.min',\n",
       "            xregexp: 'https://cdnjs.cloudflare.com/ajax/libs/xregexp/3.2.0/xregexp-all.min'\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Add the css file\n",
       "    //requirejs(['d3'],\n",
       "    //    function (d3) {\n",
       "    //        d3.select('#css').attr('href', ecco_url + 'html/styles.css')\n",
       "    //    })\n",
       "\n",
       "    console.log('Ecco initialize!!')\n",
       "\n",
       "    // returns a 'basic' object. basic.init() selects the html div we'll be\n",
       "    // rendering the html into, adds styles.css to the document.\n",
       "    define('basic', ['d3'],\n",
       "        function (d3) {\n",
       "            return {\n",
       "                init: function (viz_id = null) {\n",
       "                    if (viz_id == null) {\n",
       "                        viz_id = \"viz_\" + Math.round(Math.random() * 10000000)\n",
       "                    }\n",
       "                    // Select the div rendered below, change its id\n",
       "                    const div = d3.select('#basic').attr('id', viz_id),\n",
       "                        div_parent = d3.select('#' + viz_id).node().parentNode\n",
       "\n",
       "                    // Link to CSS file\n",
       "                    d3.select(div_parent).insert('link')\n",
       "                        .attr('rel', 'stylesheet')\n",
       "                        .attr('type', 'text/css')\n",
       "                        .attr('href', ecco_url + 'html/0.0.2/styles.css')\n",
       "\n",
       "                    return viz_id\n",
       "                }\n",
       "            }\n",
       "        }, function (err) {\n",
       "            console.log(err);\n",
       "        }\n",
       "    )\n",
       "</script>\n",
       "\n",
       "<head>\n",
       "    <link id='css' rel=\"stylesheet\" type=\"text/css\">\n",
       "</head>\n",
       "<div id=\"basic\"></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n         requirejs(['basic', 'ecco'], function(basic, ecco){\n            const viz_id = basic.init()\n            \n            ecco.interactiveTokensAndFactorSparklines(viz_id, {'tokens': [{'token': '[CLS]', 'token_id': 101, 'type': 'input', 'position': 0}, {'token': '1', 'token_id': 1015, 'type': 'input', 'position': 1}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 2}, {'token': '2', 'token_id': 1016, 'type': 'input', 'position': 3}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 4}, {'token': '3', 'token_id': 1017, 'type': 'input', 'position': 5}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 6}, {'token': '4', 'token_id': 1018, 'type': 'input', 'position': 7}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 8}, {'token': '5', 'token_id': 1019, 'type': 'input', 'position': 9}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 10}, {'token': '6', 'token_id': 1020, 'type': 'input', 'position': 11}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 12}, {'token': '7', 'token_id': 1021, 'type': 'input', 'position': 13}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 14}, {'token': '8', 'token_id': 1022, 'type': 'input', 'position': 15}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 16}, {'token': '9', 'token_id': 1023, 'type': 'input', 'position': 17}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 18}, {'token': '10', 'token_id': 2184, 'type': 'input', 'position': 19}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 20}, {'token': '11', 'token_id': 2340, 'type': 'input', 'position': 21}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 22}, {'token': '12', 'token_id': 2260, 'type': 'input', 'position': 23}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 24}, {'token': '13', 'token_id': 2410, 'type': 'input', 'position': 25}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 26}, {'token': '14', 'token_id': 2403, 'type': 'input', 'position': 27}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 28}, {'token': '15', 'token_id': 2321, 'type': 'input', 'position': 29}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 30}, {'token': '16', 'token_id': 2385, 'type': 'input', 'position': 31}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 32}, {'token': '17', 'token_id': 2459, 'type': 'input', 'position': 33}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 34}, {'token': '18', 'token_id': 2324, 'type': 'input', 'position': 35}, {'token': '[SEP]', 'token_id': 102, 'type': 'input', 'position': 36}], 'factors': [[[0.02329481951892376, 0.0455729179084301, 0.16986608505249023, 0.060972776263952255, 0.18649166822433472, 0.06762471795082092, 0.18981926143169403, 0.06934554129838943, 0.19237422943115234, 0.07181701064109802, 0.19065725803375244, 0.06969749927520752, 0.1946103572845459, 0.07663470506668091, 0.19342543184757233, 0.07394378632307053, 0.1927676498889923, 0.0730939581990242, 0.1888425499200821, 0.07162519544363022, 0.18729867041110992, 0.07065580785274506, 0.1895591914653778, 0.07358793914318085, 0.19036315381526947, 0.07323011010885239, 0.18990425765514374, 0.07166846841573715, 0.1908087134361267, 0.06813716143369675, 0.18770051002502441, 0.06859199702739716, 0.18744732439517975, 0.06751741468906403, 0.17264722287654877, 0.05893239378929138, 0.0], [0.023933488875627518, 0.006182764191180468, 0.0, 0.005666535813361406, 0.0, 0.0056093838065862656, 0.0, 0.005968625191599131, 0.0, 0.0067087034694850445, 0.0, 0.006810443475842476, 0.0, 0.0065728649497032166, 0.0, 0.00691770575940609, 0.0, 0.007959726266562939, 0.0, 0.007827055640518665, 0.0, 0.007608471903949976, 0.0, 0.009457442909479141, 0.0, 0.00938511174172163, 0.0, 0.008215868845582008, 0.0, 0.009270643815398216, 0.0, 0.00915378425270319, 0.0, 0.010620161890983582, 0.0022683681454509497, 0.013894429430365562, 1.1839704513549805]]]},\n            {\n            'hltrCFG': {'tokenization_config': {\"token_prefix\": \"\", \"partial_token_prefix\": \"##\"}\n                }\n            })\n         }, function (err) {\n            console.log(err);\n        })",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18\"\n",
    "inputs = lm.tokenizer([text], return_tensors=\"pt\")\n",
    "output = lm(inputs)\n",
    "nnmf_example1 = output.run_nmf(n_components=2)\n",
    "nnmf_example1.explore()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By hovering over each \"factor\", you can see how each token responded by the specific factor. In the example above, factor 1 seemed to respond to the commas, factor 2 the [SEP] token and factor 3 to the numbers of the simple sequence.\n",
    "But what if this explaining step could be automatized?\n",
    "I tried using openai's large language models for this - an example can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nThis cluster responds to the last token in the sequence, which appears to mark the end of the input.',\n",
       " '\\nThis factor responds to the [CLS] token at the beginning and the [SEP] token at the end of the sequence, but no other intuitive connection between the tokens was found.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnmf_example1.explain()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nnmf provides a value for how much each tokes relates to the each factor - this value is used by ECCO to colour the tokens above.\n",
    "I turned the these values into text by masking the original input sequence using the nnmf values, and masking all values under some threshold.\n",
    "I experimented with several different methods for finding a good threshold for masking, and 0.01 generally provided reasonable results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of .explain() method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explain method mainly uses 2 techniques to guide/ground the model in making the summaries!\n",
    "The first method is known as in-context learning (Dong et, al. 2022) - providing the model with a few examples of what you want it to do (and how to respond if it can't)!\n",
    "In the \"promp.py\" file, I've written the prompt used by the explain method. \n",
    "However, I quickly ran into trouble, since I wanted the model to have examples of different types of input.\n",
    "I wanted it to provide appropriate summaries of snippets of code, as well as poems.\n",
    "For this reason I quickly ran out of space, since the maximum context-length of the model I was using was 4097!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common way of adressing this issue is by employing the second technique: indexing.\n",
    "By embedding each of my example prompts + explanations in a vector space I am able to pull the most similiar examples (those closest in this embedded vector space), and use these specific examples to ground the model.\n",
    "This way, It's possible to have a large amount of highly specific instructions, from which the model can extract the most relevant information.\n",
    "I manually analyzed some examples, embedded them using openai's embedding model: \"text-embedding-ada-002\", and wrote a customized search class (in embedding_searcher.py) which found the most relevant examples, and wrote a method to add the examples, until no more could fit in the prompt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, this is how .explain() (sort of) works - by creating some additional \"factual\" information that the LLM can use, as well as a way of \"choosing\" from this pool of specialized knowledge.\n",
    "Using this specialized knowledge in combination with its huge background training - I hoped to automatize a bit of explainability, without having to fine-tune!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .explain() yourself!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, I'll let GPT-3.5 analyze this short poem written by GPT-3.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem = \"\"\"\n",
    "A robot small yet smart and bright,\n",
    "With features that delight the sight,\n",
    "Anki Vector's the name to know,\n",
    "A friend that's more than just a show.\n",
    "\n",
    "He rolls around and scans the room,\n",
    "With sensors that dispel the gloom,\n",
    "He recognizes faces and can hear,\n",
    "Your voice and commands he holds dear.\n",
    "\n",
    "A charming bot that loves to play,\n",
    "And keep you company all day,\n",
    "Anki Vector, oh how we adore,\n",
    "A companion we can't ignore. \n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this poem is much more complex than the counting sequence, let's just look at only the final layer, and let's assume that more components might be appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html lang=\"en\">\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "    var ecco_url = 'https://storage.googleapis.com/ml-intro/ecco/'\n",
       "    //var ecco_url = 'http://localhost:8000/'\n",
       "\n",
       "    if (window.ecco === undefined) window.ecco = {}\n",
       "\n",
       "    // Setup the paths of the script we'll be using\n",
       "    requirejs.config({\n",
       "        urlArgs: \"bust=\" + (new Date()).getTime(),\n",
       "        nodeRequire: require,\n",
       "        paths: {\n",
       "            d3: \"https://d3js.org/d3.v6.min\", // This is only for use in setup.html and basic.html\n",
       "            \"d3-array\": \"https://d3js.org/d3-array.v2.min\",\n",
       "            jquery: \"https://code.jquery.com/jquery-3.5.1.min\",\n",
       "            ecco: ecco_url + 'js/0.0.6/ecco-bundle.min',\n",
       "            xregexp: 'https://cdnjs.cloudflare.com/ajax/libs/xregexp/3.2.0/xregexp-all.min'\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Add the css file\n",
       "    //requirejs(['d3'],\n",
       "    //    function (d3) {\n",
       "    //        d3.select('#css').attr('href', ecco_url + 'html/styles.css')\n",
       "    //    })\n",
       "\n",
       "    console.log('Ecco initialize!!')\n",
       "\n",
       "    // returns a 'basic' object. basic.init() selects the html div we'll be\n",
       "    // rendering the html into, adds styles.css to the document.\n",
       "    define('basic', ['d3'],\n",
       "        function (d3) {\n",
       "            return {\n",
       "                init: function (viz_id = null) {\n",
       "                    if (viz_id == null) {\n",
       "                        viz_id = \"viz_\" + Math.round(Math.random() * 10000000)\n",
       "                    }\n",
       "                    // Select the div rendered below, change its id\n",
       "                    const div = d3.select('#basic').attr('id', viz_id),\n",
       "                        div_parent = d3.select('#' + viz_id).node().parentNode\n",
       "\n",
       "                    // Link to CSS file\n",
       "                    d3.select(div_parent).insert('link')\n",
       "                        .attr('rel', 'stylesheet')\n",
       "                        .attr('type', 'text/css')\n",
       "                        .attr('href', ecco_url + 'html/0.0.2/styles.css')\n",
       "\n",
       "                    return viz_id\n",
       "                }\n",
       "            }\n",
       "        }, function (err) {\n",
       "            console.log(err);\n",
       "        }\n",
       "    )\n",
       "</script>\n",
       "\n",
       "<head>\n",
       "    <link id='css' rel=\"stylesheet\" type=\"text/css\">\n",
       "</head>\n",
       "<div id=\"basic\"></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n         requirejs(['basic', 'ecco'], function(basic, ecco){\n            const viz_id = basic.init()\n            \n            ecco.interactiveTokensAndFactorSparklines(viz_id, {'tokens': [{'token': '[CLS]', 'token_id': 101, 'type': 'input', 'position': 0}, {'token': 'a', 'token_id': 1037, 'type': 'input', 'position': 1}, {'token': 'robot', 'token_id': 8957, 'type': 'input', 'position': 2}, {'token': 'small', 'token_id': 2235, 'type': 'input', 'position': 3}, {'token': 'yet', 'token_id': 2664, 'type': 'input', 'position': 4}, {'token': 'smart', 'token_id': 6047, 'type': 'input', 'position': 5}, {'token': 'and', 'token_id': 1998, 'type': 'input', 'position': 6}, {'token': 'bright', 'token_id': 4408, 'type': 'input', 'position': 7}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 8}, {'token': 'with', 'token_id': 2007, 'type': 'input', 'position': 9}, {'token': 'features', 'token_id': 2838, 'type': 'input', 'position': 10}, {'token': 'that', 'token_id': 2008, 'type': 'input', 'position': 11}, {'token': 'delight', 'token_id': 12208, 'type': 'input', 'position': 12}, {'token': 'the', 'token_id': 1996, 'type': 'input', 'position': 13}, {'token': 'sight', 'token_id': 4356, 'type': 'input', 'position': 14}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 15}, {'token': 'an', 'token_id': 2019, 'type': 'input', 'position': 16}, {'token': '##ki', 'token_id': 3211, 'type': 'input', 'position': 17}, {'token': 'vector', 'token_id': 9207, 'type': 'input', 'position': 18}, {'token': \"'\", 'token_id': 1005, 'type': 'input', 'position': 19}, {'token': 's', 'token_id': 1055, 'type': 'input', 'position': 20}, {'token': 'the', 'token_id': 1996, 'type': 'input', 'position': 21}, {'token': 'name', 'token_id': 2171, 'type': 'input', 'position': 22}, {'token': 'to', 'token_id': 2000, 'type': 'input', 'position': 23}, {'token': 'know', 'token_id': 2113, 'type': 'input', 'position': 24}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 25}, {'token': 'a', 'token_id': 1037, 'type': 'input', 'position': 26}, {'token': 'friend', 'token_id': 2767, 'type': 'input', 'position': 27}, {'token': 'that', 'token_id': 2008, 'type': 'input', 'position': 28}, {'token': \"'\", 'token_id': 1005, 'type': 'input', 'position': 29}, {'token': 's', 'token_id': 1055, 'type': 'input', 'position': 30}, {'token': 'more', 'token_id': 2062, 'type': 'input', 'position': 31}, {'token': 'than', 'token_id': 2084, 'type': 'input', 'position': 32}, {'token': 'just', 'token_id': 2074, 'type': 'input', 'position': 33}, {'token': 'a', 'token_id': 1037, 'type': 'input', 'position': 34}, {'token': 'show', 'token_id': 2265, 'type': 'input', 'position': 35}, {'token': '.', 'token_id': 1012, 'type': 'input', 'position': 36}, {'token': 'he', 'token_id': 2002, 'type': 'input', 'position': 37}, {'token': 'rolls', 'token_id': 9372, 'type': 'input', 'position': 38}, {'token': 'around', 'token_id': 2105, 'type': 'input', 'position': 39}, {'token': 'and', 'token_id': 1998, 'type': 'input', 'position': 40}, {'token': 'scans', 'token_id': 27404, 'type': 'input', 'position': 41}, {'token': 'the', 'token_id': 1996, 'type': 'input', 'position': 42}, {'token': 'room', 'token_id': 2282, 'type': 'input', 'position': 43}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 44}, {'token': 'with', 'token_id': 2007, 'type': 'input', 'position': 45}, {'token': 'sensors', 'token_id': 13907, 'type': 'input', 'position': 46}, {'token': 'that', 'token_id': 2008, 'type': 'input', 'position': 47}, {'token': 'di', 'token_id': 4487, 'type': 'input', 'position': 48}, {'token': '##sp', 'token_id': 13102, 'type': 'input', 'position': 49}, {'token': '##el', 'token_id': 2884, 'type': 'input', 'position': 50}, {'token': 'the', 'token_id': 1996, 'type': 'input', 'position': 51}, {'token': 'gloom', 'token_id': 24067, 'type': 'input', 'position': 52}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 53}, {'token': 'he', 'token_id': 2002, 'type': 'input', 'position': 54}, {'token': 'recognizes', 'token_id': 14600, 'type': 'input', 'position': 55}, {'token': 'faces', 'token_id': 5344, 'type': 'input', 'position': 56}, {'token': 'and', 'token_id': 1998, 'type': 'input', 'position': 57}, {'token': 'can', 'token_id': 2064, 'type': 'input', 'position': 58}, {'token': 'hear', 'token_id': 2963, 'type': 'input', 'position': 59}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 60}, {'token': 'your', 'token_id': 2115, 'type': 'input', 'position': 61}, {'token': 'voice', 'token_id': 2376, 'type': 'input', 'position': 62}, {'token': 'and', 'token_id': 1998, 'type': 'input', 'position': 63}, {'token': 'commands', 'token_id': 10954, 'type': 'input', 'position': 64}, {'token': 'he', 'token_id': 2002, 'type': 'input', 'position': 65}, {'token': 'holds', 'token_id': 4324, 'type': 'input', 'position': 66}, {'token': 'dear', 'token_id': 6203, 'type': 'input', 'position': 67}, {'token': '.', 'token_id': 1012, 'type': 'input', 'position': 68}, {'token': 'a', 'token_id': 1037, 'type': 'input', 'position': 69}, {'token': 'charming', 'token_id': 11951, 'type': 'input', 'position': 70}, {'token': 'bot', 'token_id': 28516, 'type': 'input', 'position': 71}, {'token': 'that', 'token_id': 2008, 'type': 'input', 'position': 72}, {'token': 'loves', 'token_id': 7459, 'type': 'input', 'position': 73}, {'token': 'to', 'token_id': 2000, 'type': 'input', 'position': 74}, {'token': 'play', 'token_id': 2377, 'type': 'input', 'position': 75}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 76}, {'token': 'and', 'token_id': 1998, 'type': 'input', 'position': 77}, {'token': 'keep', 'token_id': 2562, 'type': 'input', 'position': 78}, {'token': 'you', 'token_id': 2017, 'type': 'input', 'position': 79}, {'token': 'company', 'token_id': 2194, 'type': 'input', 'position': 80}, {'token': 'all', 'token_id': 2035, 'type': 'input', 'position': 81}, {'token': 'day', 'token_id': 2154, 'type': 'input', 'position': 82}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 83}, {'token': 'an', 'token_id': 2019, 'type': 'input', 'position': 84}, {'token': '##ki', 'token_id': 3211, 'type': 'input', 'position': 85}, {'token': 'vector', 'token_id': 9207, 'type': 'input', 'position': 86}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 87}, {'token': 'oh', 'token_id': 2821, 'type': 'input', 'position': 88}, {'token': 'how', 'token_id': 2129, 'type': 'input', 'position': 89}, {'token': 'we', 'token_id': 2057, 'type': 'input', 'position': 90}, {'token': 'ad', 'token_id': 4748, 'type': 'input', 'position': 91}, {'token': '##ore', 'token_id': 5686, 'type': 'input', 'position': 92}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 93}, {'token': 'a', 'token_id': 1037, 'type': 'input', 'position': 94}, {'token': 'companion', 'token_id': 7452, 'type': 'input', 'position': 95}, {'token': 'we', 'token_id': 2057, 'type': 'input', 'position': 96}, {'token': 'can', 'token_id': 2064, 'type': 'input', 'position': 97}, {'token': \"'\", 'token_id': 1005, 'type': 'input', 'position': 98}, {'token': 't', 'token_id': 1056, 'type': 'input', 'position': 99}, {'token': 'ignore', 'token_id': 8568, 'type': 'input', 'position': 100}, {'token': '.', 'token_id': 1012, 'type': 'input', 'position': 101}, {'token': '[SEP]', 'token_id': 102, 'type': 'input', 'position': 102}], 'factors': [[[0.0056580365635454655, 0.019136572256684303, 0.0032005971297621727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0015864702872931957, 0.0, 0.0, 0.003500869031995535, 0.00047159724636003375, 0.0, 0.0020896317437291145, 0.0, 0.007245686836540699, 0.0373653769493103, 0.02232358790934086, 0.03717714548110962, 0.0, 0.003029723884537816, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4138317108154297, 0.03348573297262192, 0.005766427610069513, 0.0, 0.002140629570931196, 0.0, 0.009598161093890667, 0.9398507475852966, 0.005828477907925844, 0.02722809836268425, 0.023750707507133484, 0.0, 0.0420384556055069, 0.019977906718850136, 0.0, 0.007561580743640661, 0.0, 0.014779306016862392, 0.0, 0.009799116291105747, 0.023143025115132332, 0.0012090728851035237, 0.010115247219800949, 0.0029271291568875313, 0.0006422974984161556, 0.005780474282801151, 0.016681775450706482, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00362111022695899, 0.0, 0.0, 0.0, 0.0, 0.01937248185276985, 0.0, 0.044065047055482864, 0.0, 0.0024339547380805016, 0.00745583837851882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008121117018163204, 0.00014958447718527168, 0.0, 0.0, 0.0, 0.00451207160949707, 0.0028904424980282784, 0.0016810535453259945, 0.0, 0.0, 0.0, 0.011248694732785225, 0.017233671620488167, 0.0002650141541380435, 0.0, 0.0, 0.0, 0.0044111283496022224, 0.0, 0.9125887751579285, 0.016393963247537613, 0.0, 0.17238087952136993, 0.7312213778495789], [0.07822563499212265, 0.24314886331558228, 0.11400458961725235, 0.25408655405044556, 0.299532413482666, 0.2565724551677704, 0.3692478537559509, 0.15812954306602478, 0.07775447517633438, 0.351127952337265, 0.17370522022247314, 0.356966495513916, 0.13988924026489258, 0.2806171774864197, 0.0887320265173912, 0.0, 0.30472061038017273, 0.3296374976634979, 0.1362902969121933, 0.40358805656433105, 0.4125130772590637, 0.3378036916255951, 0.14803056418895721, 0.28184062242507935, 0.26289835572242737, 0.024555470794439316, 0.2614120841026306, 0.0825209692120552, 0.4051561653614044, 0.3368084132671356, 0.4400482475757599, 0.3964436650276184, 0.4403226971626282, 0.29251816868782043, 0.24651122093200684, 0.10428206622600555, 0.0, 0.33606481552124023, 0.30309823155403137, 0.2742624282836914, 0.4486582577228546, 0.37543871998786926, 0.4472675323486328, 0.23952564597129822, 0.06384702771902084, 0.22282853722572327, 0.18312150239944458, 0.37695878744125366, 0.3191545605659485, 0.3480823040008545, 0.37758302688598633, 0.3297148048877716, 0.11565172672271729, 0.006649501621723175, 0.30072054266929626, 0.31172072887420654, 0.14180035889148712, 0.3719467222690582, 0.39738839864730835, 0.2487098127603531, 0.004642946179956198, 0.2118159532546997, 0.18094655871391296, 0.24938902258872986, 0.15297089517116547, 0.28986018896102905, 0.31069037318229675, 0.2011374533176422, 0.2355133593082428, 0.3295783996582031, 0.13722261786460876, 0.1425325870513916, 0.4632553458213806, 0.3503817915916443, 0.38596853613853455, 0.20869553089141846, 0.0, 0.2745862901210785, 0.35054630041122437, 0.25171738862991333, 0.19216425716876984, 0.47451362013816833, 0.27607449889183044, 0.1529666632413864, 0.34572234749794006, 0.3398762047290802, 0.16359470784664154, 0.044584810733795166, 0.20053529739379883, 0.34235116839408875, 0.2743670344352722, 0.3860754072666168, 0.27541056275367737, 0.04160900041460991, 0.3226635456085205, 0.1330825686454773, 0.35752126574516296, 0.4277074933052063, 0.0, 0.37850627303123474, 0.19227588176727295, 0.11688690632581711, 0.18327797949314117], [0.0, 0.008256562054157257, 0.0031562999356538057, 0.0028811327647417784, 0.015624545514583588, 0.0, 0.02458811365067959, 0.002731860848143697, 0.5138940215110779, 0.004217864014208317, 0.0, 0.0004274777602404356, 0.0, 0.01209147460758686, 0.0011925330618396401, 0.4938544034957886, 0.002573697827756405, 0.0, 0.00018102630565408617, 0.0036009130999445915, 0.0, 0.012139150872826576, 0.00835810974240303, 0.0067602344788610935, 0.0040906998328864574, 0.5462803840637207, 0.011561288498342037, 0.0, 0.011066045612096786, 0.15591388940811157, 0.0, 0.010463657788932323, 0.013431365601718426, 0.012933110818266869, 0.007427961565554142, 0.002142995595932007, 0.0, 0.0002062718413071707, 0.0, 0.010695326142013073, 0.0243788193911314, 0.0, 0.006937380880117416, 0.0, 0.4433450996875763, 0.011866427026689053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010837182402610779, 0.00021417051902972162, 0.47580137848854065, 0.0022774673998355865, 0.0, 0.005235678981989622, 0.017255090177059174, 0.0, 0.0, 0.4013800024986267, 0.0006289931479841471, 0.0, 0.020898906514048576, 0.0, 0.009099933318793774, 0.0, 0.0018676427425816655, 0.0816311463713646, 0.005246296990662813, 0.0, 0.00032308584195561707, 0.01167613361030817, 0.0, 0.0, 0.0008916433434933424, 0.4928359389305115, 0.010179038159549236, 0.0, 0.01524956151843071, 0.0037025040946900845, 0.0, 0.01188736967742443, 0.3527143597602844, 0.0037975339218974113, 0.0, 0.002261747606098652, 0.38262349367141724, 0.008277729153633118, 0.0, 0.003504048800095916, 0.0, 0.0, 0.4748568832874298, 0.00853144470602274, 0.0026164627633988857, 0.0, 0.0, 0.03525586798787117, 0.0, 0.0, 0.09727658331394196, 0.1033691018819809]]]},\n            {\n            'hltrCFG': {'tokenization_config': {\"token_prefix\": \"\", \"partial_token_prefix\": \"##\"}\n                }\n            })\n         }, function (err) {\n            console.log(err);\n        })",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = lm.tokenizer([poem], return_tensors=\"pt\")\n",
    "output = lm(inputs)\n",
    "nnmf_example2 = output.run_nmf(n_components=3, from_layer=5, to_layer=6)\n",
    "nnmf_example2.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' This cluster responds mainly to verbs like \"rolls\", \"scans\", \"recognizes\" and \"holds\" which are associated with the robot\\'s actions. Additionally, it responds to possessive pronouns like \"\\'s\" which link the robot to its attributes.',\n",
       " '\\nThis factor responds to the [CLS], [SEP] and \"an ##ki vector\"\\'s tokens more often than others, but does not show a clear connection between other tokens.',\n",
       " '\\nThis cluster responds to very few tokens, consisting of the [CLS] token and the [SEP] token, as well as conjunctions like \"yet\", \"and\" or \"but\".']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnmf_example2.explain()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above have the clusters jumbled - which seems to happen because of the order used by the list-comprehension I used (which I'm changing to fix it).\n",
    "Factor 1 = cluster 3\n",
    "Factor 2 = cluster 1\n",
    "\n",
    "These results are not great, but the project was interesting!\n",
    "I think more examples would help guide it! And since I wrote the method in a way, which just adds examples, untill there are no more tokens left this technique should scale well to a larger database of examples, as well as a model with more context length.\n",
    "I think it serves well as a proof of concept, and the idea of using LLMs to analyse LLMS is super exciting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements (TODO's)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course these result could be improved! \n",
    "Some low-hanging fruits are:\n",
    "- Figure out where the order of the clusters get jumbled!\n",
    "- More (and higher quality) explanation examples.\n",
    "- A more complex masking-threshold selection (right now, the masking does not take into account, that tokens above the threshold don't all have identical values)\n",
    "- Access to models with longer context-length (GPT-4 has double the context length!)\n",
    "- Exploration of different indexing/search methods like lexical or graph-based approaches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Dong, Q., Li, L., Dai, D., Zheng, C., Wu, Z., Chang, B., ... & Sui, Z. (2022). A Survey for In-context Learning. arXiv preprint arXiv:2301.00234."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
