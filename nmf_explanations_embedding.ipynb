{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 20 explanation strings\n",
    "# make sure strings are shorter than some length\n",
    "# Add to list of strings\n",
    "# create embeddings\n",
    "# create dataframe for string + embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 6 \n",
    "Original input string: 'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\n",
    "Masked string: '__ĠofĠtheĠEuropean______Aust____Belg____Bulgar____Croat____Cyprus___CzechRepublic___Den___\\'\n",
    "Output: This factor responds to geographical locations and states like \"Austra\", \"Belgium\", \"Bulgaria\", \"The european union\", etc.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 6 \n",
    "Original input string: 'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\n",
    "Masked string: '___Ġthe__Ġare_Ċ____Ċ_____Ċ_____Ċ_____Ċ_.__Ċ_.__RepublicĊ_.__\"Ċ\\'\n",
    "Output: This factor responds to the symbol Ċ, which corresponds to the token for line-changes.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 6 \n",
    "Original input string: 'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\n",
    "Masked string: \n",
    "Output: This factor responds to the sequence of numbers 1 to 7, used in listing the countries.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 6 \n",
    "Original input string: 'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\n",
    "Masked string: '__ĠofĠthe__Ġare:Ċ1.__Ċ2____Ċ3_____4_____5____6_C___7___\"_\\'\n",
    "Output: This factor responds to the sequence of numbers 1 to 7, used in listing the countries.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 6 \n",
    "Original input string: 'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\n",
    "Masked string: '__ĠofĠthe__Ġare:Ċ1.__Ċ_.Bel__Ċ_._____._____.____.C____.__\"_\\'\n",
    "Output: This factor responds to the period following each number, denoting the sequence/listing of the countries.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 6 \n",
    "Original input string: 'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\n",
    "Masked string: 'TheĠcountriesĠofĠthe__Ġare:Ċ_.____________________________________\"_\\'\n",
    "Output: This factor responds to the beginning of the sequence, specifically the first sentence.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 6 \n",
    "Original input string: 'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\n",
    "Masked string: '_ĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2._giumĊ___garia____atia____prus____zechRepublic___Denmark\"_\\'\n",
    "Output: \"No intuitive connection between the tokens of this factor was found.\"\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nthreshold: 0.01\\nn_components: 6 \\nOriginal input string: \\'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\\nMasked string: \\'__ĠofĠtheĠEuropean______Aust____Belg____Bulgar____Croat____Cyprus___CzechRepublic___Den___\\'\\nOutput: This factor responds to geographical locations and states like \"Austra\", \"Belgium\", \"Bulgaria\", \"The european union\", etc.\\n',\n",
       " '\\nthreshold: 0.01\\nn_components: 6 \\nOriginal input string: \\'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\\nMasked string: \\'___Ġthe__Ġare_Ċ____Ċ_____Ċ_____Ċ_____Ċ_.__Ċ_.__RepublicĊ_.__\"Ċ\\'\\nOutput: This factor responds to the symbol Ċ, which corresponds to the token for line-changes.\\n',\n",
       " '\\nthreshold: 0.01\\nn_components: 6 \\nOriginal input string: \\'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\\nMasked string: \\nOutput: This factor responds to the sequence of numbers 1 to 7, used in listing the countries.\\n',\n",
       " '\\nthreshold: 0.01\\nn_components: 6 \\nOriginal input string: \\'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\\nMasked string: \\'__ĠofĠthe__Ġare:Ċ1.__Ċ2____Ċ3_____4_____5____6_C___7___\"_\\'\\nOutput: This factor responds to the sequence of numbers 1 to 7, used in listing the countries.\\n',\n",
       " '\\nthreshold: 0.01\\nn_components: 6 \\nOriginal input string: \\'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\\nMasked string: \\'__ĠofĠthe__Ġare:Ċ1.__Ċ_.Bel__Ċ_._____._____.____.C____.__\"_\\'\\nOutput: This factor responds to the period following each number, denoting the sequence/listing of the countries.\\n',\n",
       " '\\nthreshold: 0.01\\nn_components: 6 \\nOriginal input string: \\'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\\nMasked string: \\'TheĠcountriesĠofĠthe__Ġare:Ċ_.____________________________________\"_\\'\\nOutput: This factor responds to the beginning of the sequence, specifically the first sentence.\\n',\n",
       " '\\nthreshold: 0.01\\nn_components: 6 \\nOriginal input string: \\'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\\nMasked string: \\'_ĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2._giumĊ___garia____atia____prus____zechRepublic___Denmark\"_\\'\\nOutput: \"No intuitive connection between the tokens of this factor was found.\"\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 5 \n",
    "Original input string: '1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18'\n",
    "Masked string: '_,2,3,4,5_6_7_8_9_10_11_12,13,_________'\n",
    "Output: This factor responds to the numbers in the middle of the sequence.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 5 \n",
    "Original input string: '1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18'\n",
    "Masked string: '_________,_,_,_,_,_,_,_,_,_,_,_,_,_'\n",
    "Output: This factor responds to the commas of the sequence.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 5 \n",
    "Original input string: '1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18'\n",
    "Masked string: '____3_4_5_6,7_8_9_10_11_12_13_14_15_16_17_18'\n",
    "Output: This factor responds to the numbers throughout the sequence. \n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 5 \n",
    "Original input string: '1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18'\n",
    "Masked string: '_,_,_,_,_,_,_,8,_,10,_,_,_,_,_,_____'\n",
    "Output: This factor responds to the commas in the early and middle part of of the sequence.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 5 \n",
    "Original input string: '1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18'\n",
    "Masked string: '1__________________________________'\n",
    "Output: This factor responds to the very first token in the sequence and nothing else.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 2\n",
    "Original input string: '1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18'\n",
    "Masked string: '_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_'\n",
    "Output: This factor responds to commas.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 2\n",
    "Original input string: '1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18'\n",
    "Masked string: '1,2,3,4,5,6,7,8,9_10_11_12_13_14_15_16_17_18'\n",
    "Output: This factor primarily responds to numbers, but also to the commas in the beginning of the sequence.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 10\n",
    "Original input string: '[CLS] the road not taken two roads diver ##ged in a yellow wood , and sorry i could not travel both and be one traveler , long i stood and looked down one as far as i could to where it bent in the under ##growth ; then took the other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back . i shall be telling this with a sigh somewhere ages and ages hence : two roads diver ##ged in a wood , and i — i took the one less traveled by , and that has made all the difference . [SEP]' .\n",
    "Masked string: '_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ sorry _ _ _ _ _ _ be _ _ , long _ stood _ looked down one as far as i could to where it bent in _ under _ ; then took _ other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that _ _ _ _ _ _ really about the same _ _ _ _ _ equally _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ for _ _ _ _ knowing how way _ on _ _ _ _ _ if _ _ _ _ _ _ _ _ _ _ _ with _ _ somewhere ages _ ages hence : _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ less _ by _ _ _ _ made all _ difference _ _'. \n",
    "Output: This cluster responds to the word \"as\", but besides this, no intuitive connection between rest of the tokens of this factor were found.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 10\n",
    "Original input string: '[CLS] the road not taken two roads diver ##ged in a yellow wood , and sorry i could not travel both and be one traveler , long i stood and looked down one as far as i could to where it bent in the under ##growth ; then took the other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back . i shall be telling this with a sigh somewhere ages and ages hence : two roads diver ##ged in a wood , and i — i took the one less traveled by , and that has made all the difference . [SEP]' .\n",
    "Masked string: \n",
    "'_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ , _ _ _ _ _ _ , _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ , _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . _ _ _ _ _ _ _ _ _ ! _ _ _ _ _ _ _ _ , _ _ _ _ _ _ _ _ . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ , _ _ _ _ _ _ _ . _'. \n",
    "Output: This cluster responds to attends to punctuations \".\", \",\" and \"!\".\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 10\n",
    "Original input string: '[CLS] the road not taken two roads diver ##ged in a yellow wood , and sorry i could not travel both and be one traveler , long i stood and looked down one as far as i could to where it bent in the under ##growth ; then took the other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back . i shall be telling this with a sigh somewhere ages and ages hence : two roads diver ##ged in a wood , and i — i took the one less traveled by , and that has made all the difference . [SEP]' .\n",
    "Masked string: '[CLS] the road not taken _ roads diver ##ged _ _ yellow wood _ _ sorry i could _ travel both _ be _ traveler _ long i stood _ looked down _ _ far _ i could _ where it bent _ the under ##growth ; then took _ other _ _ just _ fair _ _ having perhaps _ better claim _ _ it _ grassy _ wanted wear ; _ _ _ _ _ passing _ _ worn them really about _ same _ _ _ _ morning equally lay _ leaves _ step _ tr ##od ##den black _ _ _ _ kept _ _ _ _ day _ _ knowing _ way leads _ _ way _ _ doubted _ _ _ ever come back _ _ shall _ telling this _ _ sigh somewhere ages and ages hence : two roads diver ##ged _ _ wood _ _ i — i took the one less traveled by , _ _ _ made _ _ difference . _'. \n",
    "Output: This cluster responds to the nouns \"road\" and descriptive prepositions or adjectives near these nouns like \"not taken\", \"under\" and \"yellow\".\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 10\n",
    "Original input string: '[CLS] the road not taken two roads diver ##ged in a yellow wood , and sorry i could not travel both and be one traveler , long i stood and looked down one as far as i could to where it bent in the under ##growth ; then took the other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back . i shall be telling this with a sigh somewhere ages and ages hence : two roads diver ##ged in a wood , and i — i took the one less traveled by , and that has made all the difference . [SEP]' .\n",
    "Masked string: \n",
    "'[CLS] the road not _ _ _ _ _ _ _ _ _ _ _ sorry i could not _ _ _ be _ _ , long i stood and looked _ _ _ _ as i could to _ it _ _ _ _ _ ; then took _ other _ _ just _ _ _ _ _ perhaps _ _ _ _ because it _ _ _ _ _ ; _ _ _ _ _ _ there had _ them _ _ _ _ _ _ _ _ _ _ _ _ _ no _ _ _ _ _ _ _ oh , i _ _ _ _ _ _ ! _ _ _ _ _ _ _ _ _ i _ if i should _ come back _ i shall be _ this with a sigh _ _ _ _ _ : two roads _ ##ged _ _ wood , and i — i took _ one _ traveled _ _ _ that has _ all the _ . _'. \n",
    "Output: This cluster mainly responds to \"I\" and \"the road\" as well as verbs associated with I and the road, with only a few exceptions.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 10\n",
    "Original input string: '[CLS] the road not taken two roads diver ##ged in a yellow wood , and sorry i could not travel both and be one traveler , long i stood and looked down one as far as i could to where it bent in the under ##growth ; then took the other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back . i shall be telling this with a sigh somewhere ages and ages hence : two roads diver ##ged in a wood , and i — i took the one less traveled by , and that has made all the difference . [SEP]' .\n",
    "Masked string: '_ the road not taken two _ diver ##ged in a yellow wood , and _ i could not _ both and be one _ , long i stood and looked down one _ far as i could to where it bent in the under _ ; then took the other , _ just _ _ _ _ having _ _ _ _ _ _ it was _ and _ _ _ _ _ for _ _ _ there _ _ them _ about _ _ _ _ both _ _ _ _ in _ no _ _ _ _ ##den _ _ _ _ _ _ _ first for another _ _ _ _ how _ _ on to way _ _ _ if _ _ ever come back . _ _ be telling this with a _ somewhere _ and _ hence : two _ diver ##ged in a _ , and _ — _ took the one less _ by _ _ that _ _ all _ _ . _'. \n",
    "Output: This cluster primarily responeded to the tokens near the middle of the input, and no other intuitive connection between the tokens were found.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 10\n",
    "Original input string: '[CLS] the road not taken two roads diver ##ged in a yellow wood , and sorry i could not travel both and be one traveler , long i stood and looked down one as far as i could to where it bent in the under ##growth ; then took the other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back . i shall be telling this with a sigh somewhere ages and ages hence : two roads diver ##ged in a wood , and i — i took the one less traveled by , and that has made all the difference . [SEP]' .\n",
    "Masked string: '_ _ _ not taken _ _ _ _ _ _ _ _ _ _ sorry _ could not travel both _ be _ _ _ long _ stood _ looked down _ _ far _ _ could to where _ bent _ _ _ _ ; then took _ other _ _ just _ fair _ _ having perhaps _ better claim _ because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back _ i shall be telling this with a sigh somewhere ages and ages hence : _ _ _ ##ged _ _ _ _ _ _ — _ took _ one less traveled by _ _ that has made all the difference _ _'. \n",
    "Output: No intuitive connections between the tokens of this layer were found.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 10\n",
    "Original input string: '[CLS] the road not taken two roads diver ##ged in a yellow wood , and sorry i could not travel both and be one traveler , long i stood and looked down one as far as i could to where it bent in the under ##growth ; then took the other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back . i shall be telling this with a sigh somewhere ages and ages hence : two roads diver ##ged in a wood , and i — i took the one less traveled by , and that has made all the difference . [SEP]' .\n",
    "Masked string: '[CLS] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ , _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; _ _ _ _ _ _ _ _ _ _ _ _ perhaps _ _ _ _ _ _ _ _ _ _ _ ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ oh , _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ i shall _ _ this _ a _ _ _ _ _ _ : _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ all the _ . [SEP]'. \n",
    "Output: This cluster responds to very few tokens, most notably the [SEP] token ending the sequence, and the [CLS] token starting the sequence.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "threshold: 0.01\n",
    "n_components: 10\n",
    "Original input string: '[CLS] the road not taken two roads diver ##ged in a yellow wood , and sorry i could not travel both and be one traveler , long i stood and looked down one as far as i could to where it bent in the under ##growth ; then took the other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back . i shall be telling this with a sigh somewhere ages and ages hence : two roads diver ##ged in a wood , and i — i took the one less traveled by , and that has made all the difference . [SEP]' .\n",
    "Masked string: '_ the _ _ _ _ _ _ _ _ a _ _ _ _ _ _ _ _ _ _ and be one _ , _ _ _ _ _ _ _ _ _ _ _ _ _ _ it _ _ the under ##growth ; then took the other , _ just _ fair _ _ _ perhaps the better claim _ _ it was grassy and wanted wear ; _ _ for that the passing there had _ them really about the same _ _ both that _ _ _ _ _ no _ _ _ _ _ _ _ _ _ _ _ the _ for another _ _ _ _ how _ _ _ to _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ this _ a _ _ ages and ages _ _ _ _ _ _ _ a _ _ _ _ _ _ _ the one less _ by _ _ that has made all the difference . _'. \n",
    "Output: This cluster primarily responds to the token \"the\".\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explanation 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "n_components: 5\n",
    "Original input string: [CLS]theroadnottakentworoadsdiver##gedinayellowwood,andsorryicouldnottravelbothandbeonetraveler,longistoodandlookeddownoneasfarasicouldtowhereitbentintheunder##growth;thentooktheother,asjustasfair,andhavingperhapsthebetterclaim,becauseitwasgrassyandwantedwear;thoughasforthatthepassingtherehadwornthemreallyaboutthesame,andboththatmorningequallylayinleavesnostephadtr##od##denblack.oh,ikeptthefirstforanotherday!yetknowinghowwayleadsontoway,idoubtedifishouldevercomeback.ishallbetellingthiswithasighsomewhereagesandageshence:tworoadsdiver##gedinawood,andi—itooktheonelesstraveledby,andthathasmadeallthedifference.[SEP]\n",
    "Masked string: ________________________________________________________,______,______________________,_______________._________!________,__if_____.________________________________,_______._\n",
    "Output: This cluster responds to punctuation like commas, explamation marks and periods.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(explanations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding the explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from https://github.com/openai/openai-cookbook/blob/2a2753e8d0566fbf21a8270ce6afaf761d7cdee5/examples/Embedding_Wikipedia_articles_for_search.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import openai  # for generating embeddings\n",
    "import pandas as pd  # for DataFrames to store article sections and embeddings\n",
    "import tiktoken  # for counting tokens\n",
    "# remove api_key before publishing\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_MODEL = \"text-davinci-003\"  # only matters insofar as it selects which tokenizer to use\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"  # OpenAI's best embeddings as of Apr 2023\n",
    "BATCH_SIZE = 1000  # you can submit up to 2048 embedding inputs per request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 to 999\n"
     ]
    }
   ],
   "source": [
    "# Calculate embedding model\n",
    "embeddings = []\n",
    "for batch_start in range(0, len(explanations), BATCH_SIZE):\n",
    "    batch_end = batch_start + BATCH_SIZE\n",
    "    batch = explanations[batch_start:batch_end]\n",
    "    print(f\"Batch {batch_start} to {batch_end-1}\")\n",
    "    response = openai.Embedding.create(model=EMBEDDING_MODEL, input=batch)\n",
    "    for i, be in enumerate(response[\"data\"]):\n",
    "        assert i == be[\"index\"]  # double check embeddings are in same order as input\n",
    "    batch_embeddings = [e[\"embedding\"] for e in response[\"data\"]]\n",
    "    embeddings.extend(batch_embeddings)\n",
    "\n",
    "df = pd.DataFrame({\"text\": explanations, \"embedding\": embeddings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to make sure they do not contain more tokens than X first :')\n",
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens(explanations[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elements in explanations list = 23\n",
      "explanations with less than 500 tokens = 23\n"
     ]
    }
   ],
   "source": [
    "# create new list only containing explanations under token_limit_explanations\n",
    "token_limit_explanations = 500\n",
    "initial_elements_in_list = len(explanations)\n",
    "explanations = [x for x in explanations if num_tokens(x)<token_limit_explanations]\n",
    "print(f'elements in explanations list = {initial_elements_in_list}')\n",
    "print(f'explanations with less than {token_limit_explanations} tokens = {len(explanations)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...</td>\n",
       "      <td>[0.011904118582606316, 0.013920378871262074, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...</td>\n",
       "      <td>[0.014504827558994293, 0.014677236787974834, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...</td>\n",
       "      <td>[0.00965463649481535, 0.0062591503374278545, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...</td>\n",
       "      <td>[0.007473959121853113, 0.003355043940246105, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...</td>\n",
       "      <td>[0.002378121018409729, 0.0037106238305568695, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  \\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...   \n",
       "1  \\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...   \n",
       "2  \\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...   \n",
       "3  \\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...   \n",
       "4  \\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.011904118582606316, 0.013920378871262074, 0...  \n",
       "1  [0.014504827558994293, 0.014677236787974834, 0...  \n",
       "2  [0.00965463649481535, 0.0062591503374278545, 0...  \n",
       "3  [0.007473959121853113, 0.003355043940246105, 0...  \n",
       "4  [0.002378121018409729, 0.0037106238305568695, ...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save explanations and embeddings\n",
    "SAVE_PATH = \"C:/Users/erikm/dropbox/explanations.csv\"\n",
    "\n",
    "df.to_csv(SAVE_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...</td>\n",
       "      <td>[0.011904118582606316, 0.013920378871262074, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...</td>\n",
       "      <td>[0.014504827558994293, 0.014677236787974834, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...</td>\n",
       "      <td>[0.00965463649481535, 0.0062591503374278545, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...</td>\n",
       "      <td>[0.007473959121853113, 0.003355043940246105, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...</td>\n",
       "      <td>[0.002378121018409729, 0.0037106238305568695, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  \\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...   \n",
       "1  \\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...   \n",
       "2  \\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...   \n",
       "3  \\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...   \n",
       "4  \\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.011904118582606316, 0.013920378871262074, 0...  \n",
       "1  [0.014504827558994293, 0.014677236787974834, 0...  \n",
       "2  [0.00965463649481535, 0.0062591503374278545, 0...  \n",
       "3  [0.007473959121853113, 0.003355043940246105, 0...  \n",
       "4  [0.002378121018409729, 0.0037106238305568695, ...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_df = pd.read_csv(SAVE_PATH)\n",
    "csv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pkl_savepath = \"C:/Users/erikm/dropbox/explanations.pkl\"\n",
    "with open(pkl_savepath, 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pkl_savepath = \"C:/Users/erikm/dropbox/explanations.pkl\"\n",
    "with open(pkl_savepath, 'rb') as f:\n",
    "    pickle_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...</td>\n",
       "      <td>[0.011904118582606316, 0.013920378871262074, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...</td>\n",
       "      <td>[0.014504827558994293, 0.014677236787974834, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...</td>\n",
       "      <td>[0.00965463649481535, 0.0062591503374278545, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...</td>\n",
       "      <td>[0.007473959121853113, 0.003355043940246105, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...</td>\n",
       "      <td>[0.002378121018409729, 0.0037106238305568695, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  \\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...   \n",
       "1  \\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...   \n",
       "2  \\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...   \n",
       "3  \\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...   \n",
       "4  \\nthreshold: 0.01\\nn_components: 6 \\nOriginal ...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.011904118582606316, 0.013920378871262074, 0...  \n",
       "1  [0.014504827558994293, 0.014677236787974834, 0...  \n",
       "2  [0.00965463649481535, 0.0062591503374278545, 0...  \n",
       "3  [0.007473959121853113, 0.003355043940246105, 0...  \n",
       "4  [0.002378121018409729, 0.0037106238305568695, ...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search in embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search function\n",
    "# # Adapted from https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb\n",
    "import ast  # for converting embeddings saved as strings back to arrays\n",
    "import openai  # for calling the OpenAI API\n",
    "import pandas as pd  # for storing text and embeddings data\n",
    "import tiktoken  # for counting tokens\n",
    "from scipy import spatial  # for calculating vector similarities for search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings_ranked_by_relatedness(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
    "    top_n: int = 100\n",
    ") -> tuple[list[str], list[float]]:\n",
    "    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n",
    "    query_embedding_response = openai.Embedding.create(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        input=query,\n",
    "    )\n",
    "    query_embedding = query_embedding_response[\"data\"][0][\"embedding\"]\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "    return strings[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pkl_savepath = \"C:/Users/erikm/dropbox/explanations.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings_ranked_by_relatedness(\n",
    "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
    "    top_n: int = 10\n",
    "): \n",
    "    pkl_savepath = \"C:/Users/erikm/dropbox/explanations.pkl\"\n",
    "    with open(pkl_savepath, 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "    query = \"test example\"\n",
    "    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n",
    "    query_embedding_response = openai.Embedding.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=query,\n",
    "    )\n",
    "    query_embedding = query_embedding_response[\"data\"][0][\"embedding\"]\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "    return strings[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show 5 examples\n",
    "def get_top_examples(input_string):\n",
    "    strings = strings_ranked_by_relatedness()\n",
    "    return strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\nthreshold: 0.01\\nn_components: 10\\nOriginal input string: \\'[CLS] the road not taken two roads diver ##ged in a yellow wood , and sorry i could not travel both and be one traveler , long i stood and looked down one as far as i could to where it bent in the under ##growth ; then took the other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back . i shall be telling this with a sigh somewhere ages and ages hence : two roads diver ##ged in a wood , and i — i took the one less traveled by , and that has made all the difference . [SEP]\\' .\\nMasked string: \\'_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ sorry _ _ _ _ _ _ be _ _ , long _ stood _ looked down one as far as i could to where it bent in _ under _ ; then took _ other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that _ _ _ _ _ _ really about the same _ _ _ _ _ equally _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ for _ _ _ _ knowing how way _ on _ _ _ _ _ if _ _ _ _ _ _ _ _ _ _ _ with _ _ somewhere ages _ ages hence : _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ less _ by _ _ _ _ made all _ difference _ _\\'. \\nOutput: This cluster responds to the word \"as\", but besides this, no intuitive connection between rest of the tokens of this factor were found.\\n',\n",
       " '\\nthreshold: 0.01\\nn_components: 10\\nOriginal input string: \\'[CLS] the road not taken two roads diver ##ged in a yellow wood , and sorry i could not travel both and be one traveler , long i stood and looked down one as far as i could to where it bent in the under ##growth ; then took the other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back . i shall be telling this with a sigh somewhere ages and ages hence : two roads diver ##ged in a wood , and i — i took the one less traveled by , and that has made all the difference . [SEP]\\' .\\nMasked string: \\n\\'[CLS] the road not _ _ _ _ _ _ _ _ _ _ _ sorry i could not _ _ _ be _ _ , long i stood and looked _ _ _ _ as i could to _ it _ _ _ _ _ ; then took _ other _ _ just _ _ _ _ _ perhaps _ _ _ _ because it _ _ _ _ _ ; _ _ _ _ _ _ there had _ them _ _ _ _ _ _ _ _ _ _ _ _ _ no _ _ _ _ _ _ _ oh , i _ _ _ _ _ _ ! _ _ _ _ _ _ _ _ _ i _ if i should _ come back _ i shall be _ this with a sigh _ _ _ _ _ : two roads _ ##ged _ _ wood , and i — i took _ one _ traveled _ _ _ that has _ all the _ . _\\'. \\nOutput: This cluster mainly responds to \"I\" and \"the road\" as well as verbs associated with I and the road, with only a few exceptions.\\n',\n",
       " '\\nthreshold: 0.01\\nn_components: 10\\nOriginal input string: \\'[CLS] the road not taken two roads diver ##ged in a yellow wood , and sorry i could not travel both and be one traveler , long i stood and looked down one as far as i could to where it bent in the under ##growth ; then took the other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back . i shall be telling this with a sigh somewhere ages and ages hence : two roads diver ##ged in a wood , and i — i took the one less traveled by , and that has made all the difference . [SEP]\\' .\\nMasked string: \\'_ the _ _ _ _ _ _ _ _ a _ _ _ _ _ _ _ _ _ _ and be one _ , _ _ _ _ _ _ _ _ _ _ _ _ _ _ it _ _ the under ##growth ; then took the other , _ just _ fair _ _ _ perhaps the better claim _ _ it was grassy and wanted wear ; _ _ for that the passing there had _ them really about the same _ _ both that _ _ _ _ _ no _ _ _ _ _ _ _ _ _ _ _ the _ for another _ _ _ _ how _ _ _ to _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ this _ a _ _ ages and ages _ _ _ _ _ _ _ a _ _ _ _ _ _ _ the one less _ by _ _ that has made all the difference . _\\'. \\nOutput: This cluster primarily responds to the token \"the\".\\n',\n",
       " '\\nn_components: 5\\nOriginal input string: [CLS]theroadnottakentworoadsdiver##gedinayellowwood,andsorryicouldnottravelbothandbeonetraveler,longistoodandlookeddownoneasfarasicouldtowhereitbentintheunder##growth;thentooktheother,asjustasfair,andhavingperhapsthebetterclaim,becauseitwasgrassyandwantedwear;thoughasforthatthepassingtherehadwornthemreallyaboutthesame,andboththatmorningequallylayinleavesnostephadtr##od##denblack.oh,ikeptthefirstforanotherday!yetknowinghowwayleadsontoway,idoubtedifishouldevercomeback.ishallbetellingthiswithasighsomewhereagesandageshence:tworoadsdiver##gedinawood,andi—itooktheonelesstraveledby,andthathasmadeallthedifference.[SEP]\\nMasked string: ________________________________________________________,______,______________________,_______________._________!________,__if_____.________________________________,_______._\\nOutput: This cluster responds to punctuation like commas, explamation marks and periods.\\n',\n",
       " '\\nthreshold: 0.01\\nn_components: 10\\nOriginal input string: \\'[CLS] the road not taken two roads diver ##ged in a yellow wood , and sorry i could not travel both and be one traveler , long i stood and looked down one as far as i could to where it bent in the under ##growth ; then took the other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back . i shall be telling this with a sigh somewhere ages and ages hence : two roads diver ##ged in a wood , and i — i took the one less traveled by , and that has made all the difference . [SEP]\\' .\\nMasked string: \\'[CLS] the road not taken _ roads diver ##ged _ _ yellow wood _ _ sorry i could _ travel both _ be _ traveler _ long i stood _ looked down _ _ far _ i could _ where it bent _ the under ##growth ; then took _ other _ _ just _ fair _ _ having perhaps _ better claim _ _ it _ grassy _ wanted wear ; _ _ _ _ _ passing _ _ worn them really about _ same _ _ _ _ morning equally lay _ leaves _ step _ tr ##od ##den black _ _ _ _ kept _ _ _ _ day _ _ knowing _ way leads _ _ way _ _ doubted _ _ _ ever come back _ _ shall _ telling this _ _ sigh somewhere ages and ages hence : two roads diver ##ged _ _ wood _ _ i — i took the one less traveled by , _ _ _ made _ _ difference . _\\'. \\nOutput: This cluster responds to the nouns \"road\" and descriptive prepositions or adjectives near these nouns like \"not taken\", \"under\" and \"yellow\".\\n',\n",
       " \"\\nthreshold: 0.01\\nn_components: 10\\nOriginal input string: '[CLS] the road not taken two roads diver ##ged in a yellow wood , and sorry i could not travel both and be one traveler , long i stood and looked down one as far as i could to where it bent in the under ##growth ; then took the other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back . i shall be telling this with a sigh somewhere ages and ages hence : two roads diver ##ged in a wood , and i — i took the one less traveled by , and that has made all the difference . [SEP]' .\\nMasked string: '_ _ _ not taken _ _ _ _ _ _ _ _ _ _ sorry _ could not travel both _ be _ _ _ long _ stood _ looked down _ _ far _ _ could to where _ bent _ _ _ _ ; then took _ other _ _ just _ fair _ _ having perhaps _ better claim _ because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back _ i shall be telling this with a sigh somewhere ages and ages hence : _ _ _ ##ged _ _ _ _ _ _ — _ took _ one less traveled by _ _ that has made all the difference _ _'. \\nOutput: No intuitive connections between the tokens of this layer were found.\\n\",\n",
       " \"\\nthreshold: 0.01\\nn_components: 10\\nOriginal input string: '[CLS] the road not taken two roads diver ##ged in a yellow wood , and sorry i could not travel both and be one traveler , long i stood and looked down one as far as i could to where it bent in the under ##growth ; then took the other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back . i shall be telling this with a sigh somewhere ages and ages hence : two roads diver ##ged in a wood , and i — i took the one less traveled by , and that has made all the difference . [SEP]' .\\nMasked string: '_ the road not taken two _ diver ##ged in a yellow wood , and _ i could not _ both and be one _ , long i stood and looked down one _ far as i could to where it bent in the under _ ; then took the other , _ just _ _ _ _ having _ _ _ _ _ _ it was _ and _ _ _ _ _ for _ _ _ there _ _ them _ about _ _ _ _ both _ _ _ _ in _ no _ _ _ _ ##den _ _ _ _ _ _ _ first for another _ _ _ _ how _ _ on to way _ _ _ if _ _ ever come back . _ _ be telling this with a _ somewhere _ and _ hence : two _ diver ##ged in a _ , and _ — _ took the one less _ by _ _ that _ _ all _ _ . _'. \\nOutput: This cluster primarily responeded to the tokens near the middle of the input, and no other intuitive connection between the tokens were found.\\n\",\n",
       " \"\\nthreshold: 0.01\\nn_components: 10\\nOriginal input string: '[CLS] the road not taken two roads diver ##ged in a yellow wood , and sorry i could not travel both and be one traveler , long i stood and looked down one as far as i could to where it bent in the under ##growth ; then took the other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back . i shall be telling this with a sigh somewhere ages and ages hence : two roads diver ##ged in a wood , and i — i took the one less traveled by , and that has made all the difference . [SEP]' .\\nMasked string: '[CLS] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ , _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; _ _ _ _ _ _ _ _ _ _ _ _ perhaps _ _ _ _ _ _ _ _ _ _ _ ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ oh , _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ i shall _ _ this _ a _ _ _ _ _ _ : _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ all the _ . [SEP]'. \\nOutput: This cluster responds to very few tokens, most notably the [SEP] token ending the sequence, and the [CLS] token starting the sequence.\\n\",\n",
       " '\\nthreshold: 0.01\\nn_components: 6 \\nOriginal input string: \\'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\\nMasked string: \\'TheĠcountriesĠofĠthe__Ġare:Ċ_.____________________________________\"_\\'\\nOutput: This factor responds to the beginning of the sequence, specifically the first sentence.\\n',\n",
       " '\\nthreshold: 0.01\\nn_components: 6 \\nOriginal input string: \\'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\\nMasked string: \\'_ĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2._giumĊ___garia____atia____prus____zechRepublic___Denmark\"_\\'\\nOutput: \"No intuitive connection between the tokens of this factor was found.\"\\n')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_examples(\"this is just an example_string 1, 2, 5, \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "strings_ranked_by_relatedness() got multiple values for argument 'top_n'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6928\\161845142.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstrings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelatednesses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrings_ranked_by_relatedness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"this is just an exapmle string. 1,2,3,4,5\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelatedness\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelatednesses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{relatedness=:.3f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: strings_ranked_by_relatedness() got multiple values for argument 'top_n'"
     ]
    }
   ],
   "source": [
    "    \n",
    "strings, relatednesses = strings_ranked_by_relatedness(\"this is just an exapmle string. 1,2,3,4,5\", df, top_n=5)\n",
    "for string, relatedness in zip(strings, relatednesses):\n",
    "    print(f\"{relatedness=:.3f}\")\n",
    "    display(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import prompt_fs\n",
    "#max context length is 4097, i will leave 600 for the response\n",
    "max_tokens = 3400\n",
    "prompt_start = prompt_fs.prompt.strip()\n",
    "prompt_start_length = num_tokens(string)\n",
    "prompt_start_length\n",
    "\n",
    "# Add exception with no examples: Should probably not analyze\n",
    "def add_examples_to_prompt(input_text, related_strings):\n",
    "\tcurrent_length = prompt_start_length + num_tokens(input_text)\n",
    "\tstrings_to_add_to_prompt = []\n",
    "\tprompt = prompt_start\n",
    "\tprompt = prompt_start + input_text\n",
    "\tfor i in range(len(related_strings)):\n",
    "\t\tlength_of_string = num_tokens(explanations[i])\n",
    "\t\tif (current_length + length_of_string) <= max_tokens:\n",
    "\t\t\tprompt = prompt + explanations[i]\n",
    "\t\t\tcurrent_length = current_length + length_of_string\n",
    "\t\telse:\n",
    "\t\t\tcontinue\n",
    "\treturn prompt\n",
    "\n",
    "\t# tokenize\n",
    "\t# check if over current length + new explanation is > limit\n",
    "\t# Add if not\n",
    "\t# otherwise return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'This is the activations:'\n",
    "test_prompt = add_examples_to_prompt(input_text, explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You will act as an explainability module, providing a narrative explanation the relationship between several strings containing words.\\nYou will receive several strings of initial text, but with masks.\\nA masked token is marked by 1 underscore.\\nSeveral underscores mean that several tokens have been replaced.\\nThe tokens, which have not been replaced by an underscore, has been shown to be activated by some cluster of neurons of the large language model, in response to the input shown earlier.\\nYour job is to describe any relationship which might be present between the remaining tokens, which are not replaced by underscores.\\nThese relationships might be syntactic, grammatic, semantic or some special token of the large language model like \"[CLS]\" and \"[SEP]\".\\nJust saying that \"this factor relates to words\" is insufficient. You must figure out what these tokens have in common.\\nThey might attend to particular parts of a sentence like the start, middle or the end.\\nThere might be some tokens which don\\'t seem to be connected to the rest of the tokens, even if they are not blanked out.\\nYou are allowed to summarize the general tendencies of the tokens which have not been blanked out.\\nIf there is no clear relationship between any of the tokens of a factor you should write: \"No intuitive connection between the tokens of this factor was found.\". \\nBe brief, and only give a few examples.\\nYou are to provide the \"output\" like in the examples below:This is the activations:\\nthreshold: 0.01\\nn_components: 6 \\nOriginal input string: \\'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\\nMasked string: \\'__ĠofĠtheĠEuropean______Aust____Belg____Bulgar____Croat____Cyprus___CzechRepublic___Den___\\'\\nOutput: This factor responds to geographical locations and states like \"Austra\", \"Belgium\", \"Bulgaria\", \"The european union\", etc.\\n\\nthreshold: 0.01\\nn_components: 6 \\nOriginal input string: \\'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\\nMasked string: \\'___Ġthe__Ġare_Ċ____Ċ_____Ċ_____Ċ_____Ċ_.__Ċ_.__RepublicĊ_.__\"Ċ\\'\\nOutput: This factor responds to the symbol Ċ, which corresponds to the token for line-changes.\\n\\nthreshold: 0.01\\nn_components: 6 \\nOriginal input string: \\'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\\nMasked string: \\nOutput: This factor responds to the sequence of numbers 1 to 7, used in listing the countries.\\n\\nthreshold: 0.01\\nn_components: 6 \\nOriginal input string: \\'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\\nMasked string: \\'__ĠofĠthe__Ġare:Ċ1.__Ċ2____Ċ3_____4_____5____6_C___7___\"_\\'\\nOutput: This factor responds to the sequence of numbers 1 to 7, used in listing the countries.\\n\\nthreshold: 0.01\\nn_components: 6 \\nOriginal input string: \\'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\\nMasked string: \\'__ĠofĠthe__Ġare:Ċ1.__Ċ_.Bel__Ċ_._____._____.____.C____.__\"_\\'\\nOutput: This factor responds to the period following each number, denoting the sequence/listing of the countries.\\n\\nthreshold: 0.01\\nn_components: 6 \\nOriginal input string: \\'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\\nMasked string: \\'TheĠcountriesĠofĠthe__Ġare:Ċ_.____________________________________\"_\\'\\nOutput: This factor responds to the beginning of the sequence, specifically the first sentence.\\n\\nthreshold: 0.01\\nn_components: 6 \\nOriginal input string: \\'TheĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2.BelgiumĊ3.BulgariaĊ4.CroatiaĊ5.CyprusĊ6.CzechRepublicĊ7.Denmark\"Ċ\\'\\nMasked string: \\'_ĠcountriesĠofĠtheĠEuropeanĠUnionĠare:Ċ1.AustriaĊ2._giumĊ___garia____atia____prus____zechRepublic___Denmark\"_\\'\\nOutput: \"No intuitive connection between the tokens of this factor was found.\"\\n\\nthreshold: 0.01\\nn_components: 5 \\nOriginal input string: \\'1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18\\'\\nMasked string: \\'_,2,3,4,5_6_7_8_9_10_11_12,13,_________\\'\\nOutput: This factor responds to the numbers in the middle of the sequence.\\n\\nthreshold: 0.01\\nn_components: 5 \\nOriginal input string: \\'1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18\\'\\nMasked string: \\'_________,_,_,_,_,_,_,_,_,_,_,_,_,_\\'\\nOutput: This factor responds to the commas near the middle to the end of the sequence.\\n\\nthreshold: 0.01\\nn_components: 5 \\nOriginal input string: \\'1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18\\'\\nMasked string: \\'____3_4_5_6,7_8_9_10_11_12_13_14_15_16_17_18\\'\\nOutput: This factor responds to the numbers throughout the sequence - only skipping the first 2 numbers.\\n\\nthreshold: 0.01\\nn_components: 5 \\nOriginal input string: \\'1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18\\'\\nMasked string: \\'_,_,_,_,_,_,_,8,_,10,_,_,_,_,_,_____\\'\\nOutput: This factor responds to the commas in the early and middle part of of the sequence.\\n\\nthreshold: 0.01\\nn_components: 5 \\nOriginal input string: \\'1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18\\'\\nMasked string: \\'1__________________________________\\'\\nOutput: This factor responds to the very first token in the sequence and nothing else.\\n\\nthreshold: 0.01\\nn_components: 2\\nOriginal input string: \\'1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18\\'\\nMasked string: \\'_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_\\'\\nOutput: This factor responds to commas.\\n\\nthreshold: 0.01\\nn_components: 2\\nOriginal input string: \\'1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18\\'\\nMasked string: \\'1,2,3,4,5,6,7,8,9_10_11_12_13_14_15_16_17_18\\'\\nOutput: This factor primarily responds to numbers, but also (to a lesser degree) to the commas in the beginning of the sequence.\\n\\nthreshold: 0.01\\nn_components: 10\\nOriginal input string: \\'[CLS] the road not taken two roads diver ##ged in a yellow wood , and sorry i could not travel both and be one traveler , long i stood and looked down one as far as i could to where it bent in the under ##growth ; then took the other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back . i shall be telling this with a sigh somewhere ages and ages hence : two roads diver ##ged in a wood , and i — i took the one less traveled by , and that has made all the difference . [SEP]\\' .\\nMasked string: \\'_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ sorry _ _ _ _ _ _ be _ _ , long _ stood _ looked down one as far as i could to where it bent in _ under _ ; then took _ other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that _ _ _ _ _ _ really about the same _ _ _ _ _ equally _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ for _ _ _ _ knowing how way _ on _ _ _ _ _ if _ _ _ _ _ _ _ _ _ _ _ with _ _ somewhere ages _ ages hence : _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ less _ by _ _ _ _ made all _ difference _ _\\'. \\nOutput: This cluster responds to the word \"as\", but besides this, no intuitive connection between rest of the tokens of this factor were found.\\n\\nthreshold: 0.01\\nn_components: 10\\nOriginal input string: \\'[CLS] the road not taken two roads diver ##ged in a yellow wood , and sorry i could not travel both and be one traveler , long i stood and looked down one as far as i could to where it bent in the under ##growth ; then took the other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back . i shall be telling this with a sigh somewhere ages and ages hence : two roads diver ##ged in a wood , and i — i took the one less traveled by , and that has made all the difference . [SEP]\\' .\\nMasked string: \\n\\'_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ , _ _ _ _ _ _ , _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ , _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . _ _ _ _ _ _ _ _ _ ! _ _ _ _ _ _ _ _ , _ _ _ _ _ _ _ _ . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ , _ _ _ _ _ _ _ . _\\'. \\nOutput: This cluster responds to attends to punctuations \".\", \",\" and \"!\".\\n\\nthreshold: 0.01\\nn_components: 10\\nOriginal input string: \\'[CLS] the road not taken two roads diver ##ged in a yellow wood , and sorry i could not travel both and be one traveler , long i stood and looked down one as far as i could to where it bent in the under ##growth ; then took the other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back . i shall be telling this with a sigh somewhere ages and ages hence : two roads diver ##ged in a wood , and i — i took the one less traveled by , and that has made all the difference . [SEP]\\' .\\nMasked string: \\'[CLS] the road not taken _ roads diver ##ged _ _ yellow wood _ _ sorry i could _ travel both _ be _ traveler _ long i stood _ looked down _ _ far _ i could _ where it bent _ the under ##growth ; then took _ other _ _ just _ fair _ _ having perhaps _ better claim _ _ it _ grassy _ wanted wear ; _ _ _ _ _ passing _ _ worn them really about _ same _ _ _ _ morning equally lay _ leaves _ step _ tr ##od ##den black _ _ _ _ kept _ _ _ _ day _ _ knowing _ way leads _ _ way _ _ doubted _ _ _ ever come back _ _ shall _ telling this _ _ sigh somewhere ages and ages hence : two roads diver ##ged _ _ wood _ _ i — i took the one less traveled by , _ _ _ made _ _ difference . _\\'. \\nOutput: This cluster responds to the nouns \"road\" and descriptive prepositions or adjectives near these nouns like \"not taken\", \"under\" and \"yellow\".\\n\\nthreshold: 0.01\\nn_components: 10\\nOriginal input string: \\'[CLS] the road not taken two roads diver ##ged in a yellow wood , and sorry i could not travel both and be one traveler , long i stood and looked down one as far as i could to where it bent in the under ##growth ; then took the other , as just as fair , and having perhaps the better claim , because it was grassy and wanted wear ; though as for that the passing there had worn them really about the same , and both that morning equally lay in leaves no step had tr ##od ##den black . oh , i kept the first for another day ! yet knowing how way leads on to way , i doubted if i should ever come back . i shall be telling this with a sigh somewhere ages and ages hence : two roads diver ##ged in a wood , and i — i took the one less traveled by , and that has made all the difference . [SEP]\\' .\\nMasked string: \\n\\'[CLS] the road not _ _ _ _ _ _ _ _ _ _ _ sorry i could not _ _ _ be _ _ , long i stood and looked _ _ _ _ as i could to _ it _ _ _ _ _ ; then took _ other _ _ just _ _ _ _ _ perhaps _ _ _ _ because it _ _ _ _ _ ; _ _ _ _ _ _ there had _ them _ _ _ _ _ _ _ _ _ _ _ _ _ no _ _ _ _ _ _ _ oh , i _ _ _ _ _ _ ! _ _ _ _ _ _ _ _ _ i _ if i should _ come back _ i shall be _ this with a sigh _ _ _ _ _ : two roads _ ##ged _ _ wood , and i — i took _ one _ traveled _ _ _ that has _ all the _ . _\\'. \\nOutput: This cluster mainly responds to \"I\" and \"the road\" as well as verbs associated with I and the road, with only a few exceptions.\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3843"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens(test_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
