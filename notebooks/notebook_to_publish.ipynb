{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable ecco!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've build a small addition to the ecco library (https://github.com/jalammar/ecco) using openai's api to automatically explain what the clusters found through non-negative matrix factorizations (NNMF) might have in common!\n",
    "I thought ecco was a nice library to build the addition to because this project was quite experimental, and the vizualisations of ecco makes it easy to do assess whether the interpretation/summary that the LLM is providing!\n",
    "Table of Content: \n",
    "- Short intro to ECCO\n",
    "- Description of .explain() method\n",
    "- .explain() in action!\n",
    "\n",
    "My git fork of ecco can be found at (https://github.com/ondonden/eccoexplain)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short intro to ECCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import ecco\n",
    "lm = ecco.from_pretrained('distilbert-base-uncased', activations=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecco is a library providing interactive visualizations to some well-known large language model analysis methods.\n",
    "It has a few pretrained models - and for this project I'll be using the \"distilbert-base-uncased\" model (https://huggingface.co/distilbert-base-uncased) since I can easily run inference locally, but the .explain() methods works for all the models in ecco.\n",
    "Below I've provided an example of the explore method, but Jay Alammar provides more indepth examples here: https://jalammar.github.io/explaining-transformers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html lang=\"en\">\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "    var ecco_url = 'https://storage.googleapis.com/ml-intro/ecco/'\n",
       "    //var ecco_url = 'http://localhost:8000/'\n",
       "\n",
       "    if (window.ecco === undefined) window.ecco = {}\n",
       "\n",
       "    // Setup the paths of the script we'll be using\n",
       "    requirejs.config({\n",
       "        urlArgs: \"bust=\" + (new Date()).getTime(),\n",
       "        nodeRequire: require,\n",
       "        paths: {\n",
       "            d3: \"https://d3js.org/d3.v6.min\", // This is only for use in setup.html and basic.html\n",
       "            \"d3-array\": \"https://d3js.org/d3-array.v2.min\",\n",
       "            jquery: \"https://code.jquery.com/jquery-3.5.1.min\",\n",
       "            ecco: ecco_url + 'js/0.0.6/ecco-bundle.min',\n",
       "            xregexp: 'https://cdnjs.cloudflare.com/ajax/libs/xregexp/3.2.0/xregexp-all.min'\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Add the css file\n",
       "    //requirejs(['d3'],\n",
       "    //    function (d3) {\n",
       "    //        d3.select('#css').attr('href', ecco_url + 'html/styles.css')\n",
       "    //    })\n",
       "\n",
       "    console.log('Ecco initialize!!')\n",
       "\n",
       "    // returns a 'basic' object. basic.init() selects the html div we'll be\n",
       "    // rendering the html into, adds styles.css to the document.\n",
       "    define('basic', ['d3'],\n",
       "        function (d3) {\n",
       "            return {\n",
       "                init: function (viz_id = null) {\n",
       "                    if (viz_id == null) {\n",
       "                        viz_id = \"viz_\" + Math.round(Math.random() * 10000000)\n",
       "                    }\n",
       "                    // Select the div rendered below, change its id\n",
       "                    const div = d3.select('#basic').attr('id', viz_id),\n",
       "                        div_parent = d3.select('#' + viz_id).node().parentNode\n",
       "\n",
       "                    // Link to CSS file\n",
       "                    d3.select(div_parent).insert('link')\n",
       "                        .attr('rel', 'stylesheet')\n",
       "                        .attr('type', 'text/css')\n",
       "                        .attr('href', ecco_url + 'html/0.0.2/styles.css')\n",
       "\n",
       "                    return viz_id\n",
       "                }\n",
       "            }\n",
       "        }, function (err) {\n",
       "            console.log(err);\n",
       "        }\n",
       "    )\n",
       "</script>\n",
       "\n",
       "<head>\n",
       "    <link id='css' rel=\"stylesheet\" type=\"text/css\">\n",
       "</head>\n",
       "<div id=\"basic\"></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n         requirejs(['basic', 'ecco'], function(basic, ecco){\n            const viz_id = basic.init()\n            \n            ecco.interactiveTokensAndFactorSparklines(viz_id, {'tokens': [{'token': '[CLS]', 'token_id': 101, 'type': 'input', 'position': 0}, {'token': '1', 'token_id': 1015, 'type': 'input', 'position': 1}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 2}, {'token': '2', 'token_id': 1016, 'type': 'input', 'position': 3}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 4}, {'token': '3', 'token_id': 1017, 'type': 'input', 'position': 5}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 6}, {'token': '4', 'token_id': 1018, 'type': 'input', 'position': 7}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 8}, {'token': '5', 'token_id': 1019, 'type': 'input', 'position': 9}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 10}, {'token': '6', 'token_id': 1020, 'type': 'input', 'position': 11}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 12}, {'token': '7', 'token_id': 1021, 'type': 'input', 'position': 13}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 14}, {'token': '8', 'token_id': 1022, 'type': 'input', 'position': 15}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 16}, {'token': '9', 'token_id': 1023, 'type': 'input', 'position': 17}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 18}, {'token': '10', 'token_id': 2184, 'type': 'input', 'position': 19}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 20}, {'token': '11', 'token_id': 2340, 'type': 'input', 'position': 21}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 22}, {'token': '12', 'token_id': 2260, 'type': 'input', 'position': 23}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 24}, {'token': '13', 'token_id': 2410, 'type': 'input', 'position': 25}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 26}, {'token': '14', 'token_id': 2403, 'type': 'input', 'position': 27}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 28}, {'token': '15', 'token_id': 2321, 'type': 'input', 'position': 29}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 30}, {'token': '16', 'token_id': 2385, 'type': 'input', 'position': 31}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 32}, {'token': '17', 'token_id': 2459, 'type': 'input', 'position': 33}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 34}, {'token': '18', 'token_id': 2324, 'type': 'input', 'position': 35}, {'token': '[SEP]', 'token_id': 102, 'type': 'input', 'position': 36}], 'factors': [[[0.02329481951892376, 0.0455729179084301, 0.16986608505249023, 0.060972776263952255, 0.18649166822433472, 0.06762471795082092, 0.18981926143169403, 0.06934554129838943, 0.19237422943115234, 0.07181701064109802, 0.19065725803375244, 0.06969749927520752, 0.1946103572845459, 0.07663470506668091, 0.19342543184757233, 0.07394378632307053, 0.1927676498889923, 0.0730939581990242, 0.1888425499200821, 0.07162519544363022, 0.18729867041110992, 0.07065580785274506, 0.1895591914653778, 0.07358793914318085, 0.19036315381526947, 0.07323011010885239, 0.18990425765514374, 0.07166846841573715, 0.1908087134361267, 0.06813716143369675, 0.18770051002502441, 0.06859199702739716, 0.18744732439517975, 0.06751741468906403, 0.17264722287654877, 0.05893239378929138, 0.0], [0.023933488875627518, 0.006182764191180468, 0.0, 0.005666535813361406, 0.0, 0.0056093838065862656, 0.0, 0.005968625191599131, 0.0, 0.0067087034694850445, 0.0, 0.006810443475842476, 0.0, 0.0065728649497032166, 0.0, 0.00691770575940609, 0.0, 0.007959726266562939, 0.0, 0.007827055640518665, 0.0, 0.007608471903949976, 0.0, 0.009457442909479141, 0.0, 0.00938511174172163, 0.0, 0.008215868845582008, 0.0, 0.009270643815398216, 0.0, 0.00915378425270319, 0.0, 0.010620161890983582, 0.0022683681454509497, 0.013894429430365562, 1.1839704513549805]]]},\n            {\n            'hltrCFG': {'tokenization_config': {\"token_prefix\": \"\", \"partial_token_prefix\": \"##\"}\n                }\n            })\n         }, function (err) {\n            console.log(err);\n        })",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18\"\n",
    "inputs = lm.tokenizer([text], return_tensors=\"pt\")\n",
    "output = lm(inputs)\n",
    "nnmf_example1 = output.run_nmf(n_components=2)\n",
    "nnmf_example1.explore()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By hovering over each \"factor\", you can see how each token responded by the specific factor. In the example above, factor 1 seemed to respond to the commas, factor 2 the [SEP] token and factor 3 to the numbers of the simple sequence.\n",
    "But what if this explaining step could be automatized?\n",
    "I tried using openai's large language models for this - an example can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nThis cluster responds to the [CLS] token at the beginning of the sequence, and the [SEP] token at the end of the sequence.',\n",
       " '\\nThis factor responds to the numbers throughout the sequence, starting at the beginning and ending at 17.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnmf_example1.explain()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nnmf provides a value for how much each tokes relates to the each factor - this value is used by ECCO to colour the tokens above.\n",
    "I turned the these values into text by masking the original input sequence using the nnmf values, and masking all values under some threshold.\n",
    "I experimented with several different methods for finding a good threshold for masking, and 0.01 generally provided reasonable results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of .explain() method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explain method mainly uses 2 techniques to guide/ground the model in making the summaries!\n",
    "The first method is known as in-context learning (Dong et, al. 2022) - providing the model with a few examples of what you want it to do (and how to respond if it can't)!\n",
    "In the \"promp.py\" file, I've written the prompt used by the explain method. \n",
    "However, I quickly ran into trouble, since I wanted the model to have examples of different types of input.\n",
    "I wanted it to provide appropriate summaries of snippets of code, as well as poems.\n",
    "For this reason I quickly ran out of space, since the maximum context-length of the model I was using was 4097!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common way of adressing this issue is by employing the second technique: indexing.\n",
    "By embedding each of my example prompts + explanations in a vector space I am able to pull the most similiar examples (those closest in this embedded vector space), and use these specific examples to ground the model.\n",
    "This way, It's possible to have a large amount of highly specific instructions, from which the model can extract the most relevant information.\n",
    "I manually analyzed some examples, embedded them using openai's embedding model: \"text-embedding-ada-002\", and wrote a customized search class (in embedding_searcher.py) which found the most relevant examples, and wrote a method to add the examples, until no more could fit in the prompt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, this is how .explain() (sort of) works - by creating some additional \"factual\" information that the LLM can use, as well as a way of \"choosing\" from this pool of specialized knowledge.\n",
    "Using this specialized knowledge in combination with its huge background training - I hoped to automatize a bit of explainability, without having to fine-tune!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .explain() yourself!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, I'll let GPT-3.5 analyze this short poem written by GPT-3.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem = \"\"\"\n",
    "A robot small yet smart and bright,\n",
    "With features that delight the sight,\n",
    "Anki Vector's the name to know,\n",
    "A friend that's more than just a show.\n",
    "\n",
    "He rolls around and scans the room,\n",
    "With sensors that dispel the gloom,\n",
    "He recognizes faces and can hear,\n",
    "Your voice and commands he holds dear.\n",
    "\n",
    "A charming bot that loves to play,\n",
    "And keep you company all day,\n",
    "Anki Vector, oh how we adore,\n",
    "A companion we can't ignore. \n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this poem is much more complex than the counting sequence, let's just look at only the final layer, and let's assume that more components might be appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html lang=\"en\">\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "    var ecco_url = 'https://storage.googleapis.com/ml-intro/ecco/'\n",
       "    //var ecco_url = 'http://localhost:8000/'\n",
       "\n",
       "    if (window.ecco === undefined) window.ecco = {}\n",
       "\n",
       "    // Setup the paths of the script we'll be using\n",
       "    requirejs.config({\n",
       "        urlArgs: \"bust=\" + (new Date()).getTime(),\n",
       "        nodeRequire: require,\n",
       "        paths: {\n",
       "            d3: \"https://d3js.org/d3.v6.min\", // This is only for use in setup.html and basic.html\n",
       "            \"d3-array\": \"https://d3js.org/d3-array.v2.min\",\n",
       "            jquery: \"https://code.jquery.com/jquery-3.5.1.min\",\n",
       "            ecco: ecco_url + 'js/0.0.6/ecco-bundle.min',\n",
       "            xregexp: 'https://cdnjs.cloudflare.com/ajax/libs/xregexp/3.2.0/xregexp-all.min'\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Add the css file\n",
       "    //requirejs(['d3'],\n",
       "    //    function (d3) {\n",
       "    //        d3.select('#css').attr('href', ecco_url + 'html/styles.css')\n",
       "    //    })\n",
       "\n",
       "    console.log('Ecco initialize!!')\n",
       "\n",
       "    // returns a 'basic' object. basic.init() selects the html div we'll be\n",
       "    // rendering the html into, adds styles.css to the document.\n",
       "    define('basic', ['d3'],\n",
       "        function (d3) {\n",
       "            return {\n",
       "                init: function (viz_id = null) {\n",
       "                    if (viz_id == null) {\n",
       "                        viz_id = \"viz_\" + Math.round(Math.random() * 10000000)\n",
       "                    }\n",
       "                    // Select the div rendered below, change its id\n",
       "                    const div = d3.select('#basic').attr('id', viz_id),\n",
       "                        div_parent = d3.select('#' + viz_id).node().parentNode\n",
       "\n",
       "                    // Link to CSS file\n",
       "                    d3.select(div_parent).insert('link')\n",
       "                        .attr('rel', 'stylesheet')\n",
       "                        .attr('type', 'text/css')\n",
       "                        .attr('href', ecco_url + 'html/0.0.2/styles.css')\n",
       "\n",
       "                    return viz_id\n",
       "                }\n",
       "            }\n",
       "        }, function (err) {\n",
       "            console.log(err);\n",
       "        }\n",
       "    )\n",
       "</script>\n",
       "\n",
       "<head>\n",
       "    <link id='css' rel=\"stylesheet\" type=\"text/css\">\n",
       "</head>\n",
       "<div id=\"basic\"></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n         requirejs(['basic', 'ecco'], function(basic, ecco){\n            const viz_id = basic.init()\n            \n            ecco.interactiveTokensAndFactorSparklines(viz_id, {'tokens': [{'token': '[CLS]', 'token_id': 101, 'type': 'input', 'position': 0}, {'token': 'a', 'token_id': 1037, 'type': 'input', 'position': 1}, {'token': 'robot', 'token_id': 8957, 'type': 'input', 'position': 2}, {'token': 'small', 'token_id': 2235, 'type': 'input', 'position': 3}, {'token': 'yet', 'token_id': 2664, 'type': 'input', 'position': 4}, {'token': 'smart', 'token_id': 6047, 'type': 'input', 'position': 5}, {'token': 'and', 'token_id': 1998, 'type': 'input', 'position': 6}, {'token': 'bright', 'token_id': 4408, 'type': 'input', 'position': 7}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 8}, {'token': 'with', 'token_id': 2007, 'type': 'input', 'position': 9}, {'token': 'features', 'token_id': 2838, 'type': 'input', 'position': 10}, {'token': 'that', 'token_id': 2008, 'type': 'input', 'position': 11}, {'token': 'delight', 'token_id': 12208, 'type': 'input', 'position': 12}, {'token': 'the', 'token_id': 1996, 'type': 'input', 'position': 13}, {'token': 'sight', 'token_id': 4356, 'type': 'input', 'position': 14}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 15}, {'token': 'an', 'token_id': 2019, 'type': 'input', 'position': 16}, {'token': '##ki', 'token_id': 3211, 'type': 'input', 'position': 17}, {'token': 'vector', 'token_id': 9207, 'type': 'input', 'position': 18}, {'token': \"'\", 'token_id': 1005, 'type': 'input', 'position': 19}, {'token': 's', 'token_id': 1055, 'type': 'input', 'position': 20}, {'token': 'the', 'token_id': 1996, 'type': 'input', 'position': 21}, {'token': 'name', 'token_id': 2171, 'type': 'input', 'position': 22}, {'token': 'to', 'token_id': 2000, 'type': 'input', 'position': 23}, {'token': 'know', 'token_id': 2113, 'type': 'input', 'position': 24}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 25}, {'token': 'a', 'token_id': 1037, 'type': 'input', 'position': 26}, {'token': 'friend', 'token_id': 2767, 'type': 'input', 'position': 27}, {'token': 'that', 'token_id': 2008, 'type': 'input', 'position': 28}, {'token': \"'\", 'token_id': 1005, 'type': 'input', 'position': 29}, {'token': 's', 'token_id': 1055, 'type': 'input', 'position': 30}, {'token': 'more', 'token_id': 2062, 'type': 'input', 'position': 31}, {'token': 'than', 'token_id': 2084, 'type': 'input', 'position': 32}, {'token': 'just', 'token_id': 2074, 'type': 'input', 'position': 33}, {'token': 'a', 'token_id': 1037, 'type': 'input', 'position': 34}, {'token': 'show', 'token_id': 2265, 'type': 'input', 'position': 35}, {'token': '.', 'token_id': 1012, 'type': 'input', 'position': 36}, {'token': 'he', 'token_id': 2002, 'type': 'input', 'position': 37}, {'token': 'rolls', 'token_id': 9372, 'type': 'input', 'position': 38}, {'token': 'around', 'token_id': 2105, 'type': 'input', 'position': 39}, {'token': 'and', 'token_id': 1998, 'type': 'input', 'position': 40}, {'token': 'scans', 'token_id': 27404, 'type': 'input', 'position': 41}, {'token': 'the', 'token_id': 1996, 'type': 'input', 'position': 42}, {'token': 'room', 'token_id': 2282, 'type': 'input', 'position': 43}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 44}, {'token': 'with', 'token_id': 2007, 'type': 'input', 'position': 45}, {'token': 'sensors', 'token_id': 13907, 'type': 'input', 'position': 46}, {'token': 'that', 'token_id': 2008, 'type': 'input', 'position': 47}, {'token': 'di', 'token_id': 4487, 'type': 'input', 'position': 48}, {'token': '##sp', 'token_id': 13102, 'type': 'input', 'position': 49}, {'token': '##el', 'token_id': 2884, 'type': 'input', 'position': 50}, {'token': 'the', 'token_id': 1996, 'type': 'input', 'position': 51}, {'token': 'gloom', 'token_id': 24067, 'type': 'input', 'position': 52}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 53}, {'token': 'he', 'token_id': 2002, 'type': 'input', 'position': 54}, {'token': 'recognizes', 'token_id': 14600, 'type': 'input', 'position': 55}, {'token': 'faces', 'token_id': 5344, 'type': 'input', 'position': 56}, {'token': 'and', 'token_id': 1998, 'type': 'input', 'position': 57}, {'token': 'can', 'token_id': 2064, 'type': 'input', 'position': 58}, {'token': 'hear', 'token_id': 2963, 'type': 'input', 'position': 59}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 60}, {'token': 'your', 'token_id': 2115, 'type': 'input', 'position': 61}, {'token': 'voice', 'token_id': 2376, 'type': 'input', 'position': 62}, {'token': 'and', 'token_id': 1998, 'type': 'input', 'position': 63}, {'token': 'commands', 'token_id': 10954, 'type': 'input', 'position': 64}, {'token': 'he', 'token_id': 2002, 'type': 'input', 'position': 65}, {'token': 'holds', 'token_id': 4324, 'type': 'input', 'position': 66}, {'token': 'dear', 'token_id': 6203, 'type': 'input', 'position': 67}, {'token': '.', 'token_id': 1012, 'type': 'input', 'position': 68}, {'token': 'a', 'token_id': 1037, 'type': 'input', 'position': 69}, {'token': 'charming', 'token_id': 11951, 'type': 'input', 'position': 70}, {'token': 'bot', 'token_id': 28516, 'type': 'input', 'position': 71}, {'token': 'that', 'token_id': 2008, 'type': 'input', 'position': 72}, {'token': 'loves', 'token_id': 7459, 'type': 'input', 'position': 73}, {'token': 'to', 'token_id': 2000, 'type': 'input', 'position': 74}, {'token': 'play', 'token_id': 2377, 'type': 'input', 'position': 75}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 76}, {'token': 'and', 'token_id': 1998, 'type': 'input', 'position': 77}, {'token': 'keep', 'token_id': 2562, 'type': 'input', 'position': 78}, {'token': 'you', 'token_id': 2017, 'type': 'input', 'position': 79}, {'token': 'company', 'token_id': 2194, 'type': 'input', 'position': 80}, {'token': 'all', 'token_id': 2035, 'type': 'input', 'position': 81}, {'token': 'day', 'token_id': 2154, 'type': 'input', 'position': 82}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 83}, {'token': 'an', 'token_id': 2019, 'type': 'input', 'position': 84}, {'token': '##ki', 'token_id': 3211, 'type': 'input', 'position': 85}, {'token': 'vector', 'token_id': 9207, 'type': 'input', 'position': 86}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 87}, {'token': 'oh', 'token_id': 2821, 'type': 'input', 'position': 88}, {'token': 'how', 'token_id': 2129, 'type': 'input', 'position': 89}, {'token': 'we', 'token_id': 2057, 'type': 'input', 'position': 90}, {'token': 'ad', 'token_id': 4748, 'type': 'input', 'position': 91}, {'token': '##ore', 'token_id': 5686, 'type': 'input', 'position': 92}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 93}, {'token': 'a', 'token_id': 1037, 'type': 'input', 'position': 94}, {'token': 'companion', 'token_id': 7452, 'type': 'input', 'position': 95}, {'token': 'we', 'token_id': 2057, 'type': 'input', 'position': 96}, {'token': 'can', 'token_id': 2064, 'type': 'input', 'position': 97}, {'token': \"'\", 'token_id': 1005, 'type': 'input', 'position': 98}, {'token': 't', 'token_id': 1056, 'type': 'input', 'position': 99}, {'token': 'ignore', 'token_id': 8568, 'type': 'input', 'position': 100}, {'token': '.', 'token_id': 1012, 'type': 'input', 'position': 101}, {'token': '[SEP]', 'token_id': 102, 'type': 'input', 'position': 102}], 'factors': [[[0.0, 0.022996362298727036, 0.004933070857077837, 0.002433532616123557, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001878493931144476, 0.0, 0.0, 0.007753503974527121, 0.001450790325179696, 0.0, 0.004334063269197941, 0.0014917633961886168, 0.009306072257459164, 0.0, 0.0, 0.04385024309158325, 0.0, 0.005201981868594885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39711517095565796, 0.0, 0.010280449874699116, 0.0, 0.005251099821180105, 0.0012183132348582149, 0.012049787677824497, 1.0827444791793823, 0.002497251844033599, 0.0, 0.02784683182835579, 0.0, 0.002471940591931343, 0.02851596102118492, 0.0, 0.007149032317101955, 0.0008179844007827342, 0.01703338697552681, 0.0, 0.007110067643225193, 0.02741367183625698, 0.0, 0.014864334836602211, 0.0042704027146101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004265286959707737, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022150930017232895, 0.048504460602998734, 0.0, 0.003704771399497986, 0.009463970549404621, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012014142237603664, 0.0019211339531466365, 0.0, 0.002999396063387394, 0.0, 0.008886580355465412, 0.007067717146128416, 0.0018725307891145349, 0.0, 0.0, 0.0, 0.010645074769854546, 0.020879900082945824, 0.0, 0.0, 0.0013137472560629249, 0.0008533977088518441, 0.0032589470501989126, 0.0, 1.0501112937927246, 0.014303254894912243, 0.0, 0.17385835945606232, 0.8340926170349121], [0.0, 0.044645313173532486, 0.0, 0.0, 0.09831459820270538, 0.0, 0.8185133934020996, 0.0, 0.10495370626449585, 0.23553650081157684, 0.0, 0.14438572525978088, 0.0, 0.008727015927433968, 0.0, 0.0, 0.07301460206508636, 0.0, 0.0, 0.11208520829677582, 0.032596465200185776, 0.0, 0.0, 0.0, 0.0, 0.01758640818297863, 0.061434853821992874, 0.0, 0.06982175260782242, 0.029544224962592125, 0.0, 0.0, 0.0, 0.0, 0.0022954281885176897, 0.0, 0.0, 0.06212582439184189, 0.0, 0.005262479186058044, 1.1224292516708374, 0.0, 0.0, 0.0, 0.01635194942355156, 0.08273405581712723, 0.0, 0.07734259963035583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007206238806247711, 0.12459677457809448, 0.0, 0.0, 0.9514225125312805, 0.08109478652477264, 0.0, 0.0, 0.06620945781469345, 0.0, 0.7987768054008484, 0.0, 0.12438050657510757, 0.0, 0.0, 0.336754709482193, 0.08965032547712326, 0.0, 0.0, 0.14778736233711243, 0.0, 0.04326038807630539, 0.0, 0.0, 0.8568323254585266, 0.0, 0.01581915095448494, 0.0, 0.020483458414673805, 0.018812745809555054, 0.0, 0.0843069851398468, 0.0, 0.0, 0.003040649928152561, 0.059361882507801056, 0.004143284168094397, 0.0, 0.005878977943211794, 0.0, 0.0, 0.06215258315205574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5987500548362732, 0.0], [0.0, 0.00900191254913807, 0.003085716161876917, 0.0012642276706174016, 0.014823155477643013, 0.0, 0.0, 0.0026259205769747496, 0.6710070967674255, 0.0, 0.0, 0.0, 0.0, 0.011394736357033253, 0.00040134863229468465, 0.6521008610725403, 0.0, 0.0, 0.0, 0.029776325449347496, 0.007209735922515392, 0.006272376514971256, 0.008268599398434162, 0.004124835599213839, 0.0027570477686822414, 0.7172878980636597, 0.009986409917473793, 0.0, 0.009777401573956013, 0.23336154222488403, 0.005602721590548754, 0.0102358628064394, 0.01389394886791706, 0.013715389184653759, 0.007397786248475313, 0.0013318571727722883, 0.0, 0.001488430774770677, 0.0, 0.013862104155123234, 0.0, 0.0, 0.0045366245321929455, 0.0, 0.5849060416221619, 0.011388742364943027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01149566937237978, 0.0, 0.6248124241828918, 0.0036753632593899965, 0.0, 0.004867670591920614, 0.0, 0.0, 0.0, 0.5281608700752258, 0.0, 0.0, 0.0, 0.0, 0.00752786872908473, 0.0, 0.0009752190671861172, 0.08373451232910156, 0.003612950211390853, 0.0, 0.0, 0.006398381665349007, 0.0, 0.0, 0.0008388590649701655, 0.6545858979225159, 0.0, 0.0, 0.016696833074092865, 0.002235237741842866, 0.0, 0.011151790618896484, 0.4623137414455414, 0.0, 0.0, 0.001815479015931487, 0.5056478381156921, 0.006559363100677729, 0.0, 0.004935289267450571, 0.0, 0.0, 0.6237993836402893, 0.005228934809565544, 0.0014700121246278286, 0.0005097170942462981, 0.0, 0.04576195403933525, 0.0, 0.0, 0.06431951373815536, 0.13630449771881104], [0.0, 0.036936938762664795, 0.020449882373213768, 0.04585941135883331, 0.04838459566235542, 0.04628046602010727, 0.021135851740837097, 0.028486497700214386, 0.010337901301681995, 0.046416278928518295, 0.029852543026208878, 0.054137490689754486, 0.0021005291491746902, 0.05037350207567215, 0.016092674806714058, 0.0, 0.05131591111421585, 0.05956442281603813, 0.024614429101347923, 0.0033682717476040125, 0.014763649553060532, 0.06355414539575577, 0.027313286438584328, 0.05174542963504791, 0.047957174479961395, 0.00591024337336421, 0.044106755405664444, 0.015240381471812725, 0.0690002292394638, 0.0, 0.010219934396445751, 0.07155013829469681, 0.07993844151496887, 0.052961450070142746, 0.04446416720747948, 0.01896451972424984, 0.0, 0.04619777575135231, 0.006259062327444553, 0.04548925906419754, 0.00830850563943386, 0.010367241688072681, 0.08061938732862473, 0.04359753429889679, 0.008017132058739662, 0.03480219841003418, 0.03142334893345833, 0.06335267424583435, 0.05052096024155617, 0.060433026403188705, 0.05651683732867241, 0.05826054513454437, 0.02089519053697586, 0.0, 0.03347596898674965, 0.0031390890944749117, 0.025939857587218285, 0.009375561028718948, 0.025158723816275597, 0.041672851890325546, 0.002614860190078616, 0.031138813123106956, 0.03292898088693619, 0.0, 0.024827638640999794, 0.0407189317047596, 0.012791762128472328, 0.03607223182916641, 0.025426222011446953, 0.05000937730073929, 0.02383025735616684, 0.02485424466431141, 0.0755036398768425, 0.017181990668177605, 0.06758445501327515, 0.03535288944840431, 0.0, 0.0, 0.052354756742715836, 0.04463975504040718, 0.03499416634440422, 0.08516986668109894, 0.04894407093524933, 0.029263023287057877, 0.05747923254966736, 0.0608859546482563, 0.02837812341749668, 0.003546103835105896, 0.03308943659067154, 0.06017124652862549, 0.0444425530731678, 0.06398075819015503, 0.03733043745160103, 0.00980254728347063, 0.0551249235868454, 0.024320129305124283, 0.05743216350674629, 0.04333796352148056, 0.0, 0.057047247886657715, 0.03402164950966835, 0.0, 0.027910791337490082], [0.05835118889808655, 0.01124299131333828, 0.00021785339049529284, 0.0, 8.318785694427788e-05, 0.0, 0.0, 0.00010465908417245373, 0.0, 0.008415235206484795, 0.004410581197589636, 0.004329031798988581, 0.06401180475950241, 0.0, 0.0, 0.0037684834096580744, 0.0, 0.0, 0.00010523467790335417, 0.18003356456756592, 0.1635989397764206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18715299665927887, 0.19938687980175018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029116250574588776, 0.14096446335315704, 0.00946551002562046, 0.02309330552816391, 0.16922496259212494, 0.0, 0.0, 0.011203409172594547, 0.0013646433362737298, 0.00488463556393981, 0.0, 0.02179364673793316, 0.006644312757998705, 0.03354679048061371, 0.0029436962213367224, 0.0, 0.00966440886259079, 0.03703620657324791, 0.15085956454277039, 0.0, 0.008147913962602615, 0.11321047693490982, 0.008184149861335754, 0.0, 0.00826690997928381, 0.0, 0.0, 0.007771805860102177, 0.011346248909831047, 0.12455031275749207, 0.0, 0.0, 0.01094007771462202, 0.002194923348724842, 0.002205662429332733, 0.0, 0.12685418128967285, 0.0, 0.006077614612877369, 0.0, 0.0023662885650992393, 0.029415801167488098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003880849340930581, 0.015188884921371937, 0.0, 0.002760776551440358, 0.014608106575906277, 0.013201523572206497, 0.03359268605709076, 0.0, 0.0, 0.0, 0.019588952884078026, 0.09187522530555725, 0.0, 0.03167715668678284, 0.0020317742601037025, 0.0, 0.017762519419193268]]]},\n            {\n            'hltrCFG': {'tokenization_config': {\"token_prefix\": \"\", \"partial_token_prefix\": \"##\"}\n                }\n            })\n         }, function (err) {\n            console.log(err);\n        })",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = lm.tokenizer([poem], return_tensors=\"pt\")\n",
    "output = lm(inputs)\n",
    "nnmf_example2 = output.run_nmf(n_components=5, from_layer=5, to_layer=6)\n",
    "nnmf_example2.explore()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this less familiar case, in spite of attempts to ground the model, it still hallucinates information in the case of factor 1 and 3 - in spite of being fed examples of activations for clusters selectively attending to punctuation and the tokens used by BERT models.\n",
    "In the case of factor 1 and 3, it adds tokens from the initial input to its attempt to summarize, rather than sticking to the masked tokens.\n",
    "It does, however, provide accurate descriptions of especially factors 2, and 5 - and correctly notes that factor 5 mainly responds to verbs, and that these are generally related to companionship in this case.\n",
    "See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nThis cluster responds to the words \"a\", \"you\", \"ad\", and \"t\", as well as punctuation and the marker \"[SEP]\".',\n",
       " '\\nThis cluster responds to the words \"a\", \"he\", \"your\", and \"an ##ki vector\". It also responds to the punctuation \".\".',\n",
       " '\\nThis cluster responds to words relating to companionship, such as \"friend\", \"company\", \"hear\", \"holds\" and \"ignore\".',\n",
       " '\\nThis cluster attends to adjectives and nouns like \"small\", \"smart\", \"bright\", \"features\", \"name\", \"friend\", \"show\", \"sensors\", \"gloom\", \"faces\", \"hear\", \"voice\", \"commands\", \"dear\", \"charming\", \"bot\", \"play\", \"company\", \"vector\" and \"companion\".',\n",
       " ' This cluster responds to verbs relating to companionship like \"recognize\", \"holds\" and \"loves\".']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnmf_example2.explain()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are not great, but the project was interesting!\n",
    "This only has 25 examples and the masking threshold as well as the quality/clarity of explanations could be improved!\n",
    "Additionally, since I wrote the method in a way, which adds examples untill there are no more tokens left this technique should scale well to a larger database of examples, as well as a model with more context length.\n",
    "I think it serves as a mediocre proof of concept, with a lot of room for improvement!\n",
    "The idea of using LLMs to analyse LLMs is super exciting - and some other methods be even more suitable to being changed to natural language than NNMF!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements (TODO's)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course these result could be improved! \n",
    "Some low-hanging fruits are:\n",
    "- More (and higher quality) explanation examples.\n",
    "- A more complex masking-threshold selection (right now, the masking does not take into account, that tokens above the threshold don't all have identical values)\n",
    "- Access to models with longer context-length (GPT-4 has double the context length!)\n",
    "- Exploration of different indexing/search methods like lexical or graph-based approaches\n",
    "- Finetuning! But this would require many more examples."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Dong, Q., Li, L., Dai, D., Zheng, C., Wu, Z., Chang, B., ... & Sui, Z. (2022). A Survey for In-context Learning. arXiv preprint arXiv:2301.00234."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
