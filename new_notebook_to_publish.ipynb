{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable ecco!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've build a small addition to the ecco library (https://github.com/jalammar/ecco) using openai's api to automatically explain what the clusters found through non-negative matrix factorizations (NNMF) might have in common!\n",
    "I thought ecco was a nice library to build the addition to because this project was quite experimental, and the vizualisations of ecco makes it easy to do assess whether the interpretation/summary that the LLM is providing!\n",
    "Table of Content: \n",
    "- Short intro to ECCO\n",
    "- Description of .explain() method\n",
    "- .explain() in action!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short intro to ECCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import ecco\n",
    "lm = ecco.from_pretrained('distilbert-base-uncased', activations=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecco is a library providing interactive visualizations to some well-known large language model analysis methods.\n",
    "It has a few pretrained models - and for this project I'll be using the \"distilbert-base-uncased\" model since I can easily run inference using the model locally, but the .explain() methods works for all the models in ecco.\n",
    "Below I've provided an example of the explore method, but Jay Alammar provides more indepth examples here: https://jalammar.github.io/explaining-transformers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html lang=\"en\">\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "    var ecco_url = 'https://storage.googleapis.com/ml-intro/ecco/'\n",
       "    //var ecco_url = 'http://localhost:8000/'\n",
       "\n",
       "    if (window.ecco === undefined) window.ecco = {}\n",
       "\n",
       "    // Setup the paths of the script we'll be using\n",
       "    requirejs.config({\n",
       "        urlArgs: \"bust=\" + (new Date()).getTime(),\n",
       "        nodeRequire: require,\n",
       "        paths: {\n",
       "            d3: \"https://d3js.org/d3.v6.min\", // This is only for use in setup.html and basic.html\n",
       "            \"d3-array\": \"https://d3js.org/d3-array.v2.min\",\n",
       "            jquery: \"https://code.jquery.com/jquery-3.5.1.min\",\n",
       "            ecco: ecco_url + 'js/0.0.6/ecco-bundle.min',\n",
       "            xregexp: 'https://cdnjs.cloudflare.com/ajax/libs/xregexp/3.2.0/xregexp-all.min'\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Add the css file\n",
       "    //requirejs(['d3'],\n",
       "    //    function (d3) {\n",
       "    //        d3.select('#css').attr('href', ecco_url + 'html/styles.css')\n",
       "    //    })\n",
       "\n",
       "    console.log('Ecco initialize!!')\n",
       "\n",
       "    // returns a 'basic' object. basic.init() selects the html div we'll be\n",
       "    // rendering the html into, adds styles.css to the document.\n",
       "    define('basic', ['d3'],\n",
       "        function (d3) {\n",
       "            return {\n",
       "                init: function (viz_id = null) {\n",
       "                    if (viz_id == null) {\n",
       "                        viz_id = \"viz_\" + Math.round(Math.random() * 10000000)\n",
       "                    }\n",
       "                    // Select the div rendered below, change its id\n",
       "                    const div = d3.select('#basic').attr('id', viz_id),\n",
       "                        div_parent = d3.select('#' + viz_id).node().parentNode\n",
       "\n",
       "                    // Link to CSS file\n",
       "                    d3.select(div_parent).insert('link')\n",
       "                        .attr('rel', 'stylesheet')\n",
       "                        .attr('type', 'text/css')\n",
       "                        .attr('href', ecco_url + 'html/0.0.2/styles.css')\n",
       "\n",
       "                    return viz_id\n",
       "                }\n",
       "            }\n",
       "        }, function (err) {\n",
       "            console.log(err);\n",
       "        }\n",
       "    )\n",
       "</script>\n",
       "\n",
       "<head>\n",
       "    <link id='css' rel=\"stylesheet\" type=\"text/css\">\n",
       "</head>\n",
       "<div id=\"basic\"></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n         requirejs(['basic', 'ecco'], function(basic, ecco){\n            const viz_id = basic.init()\n            \n            ecco.interactiveTokensAndFactorSparklines(viz_id, {'tokens': [{'token': '[CLS]', 'token_id': 101, 'type': 'input', 'position': 0}, {'token': '1', 'token_id': 1015, 'type': 'input', 'position': 1}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 2}, {'token': '2', 'token_id': 1016, 'type': 'input', 'position': 3}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 4}, {'token': '3', 'token_id': 1017, 'type': 'input', 'position': 5}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 6}, {'token': '4', 'token_id': 1018, 'type': 'input', 'position': 7}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 8}, {'token': '5', 'token_id': 1019, 'type': 'input', 'position': 9}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 10}, {'token': '6', 'token_id': 1020, 'type': 'input', 'position': 11}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 12}, {'token': '7', 'token_id': 1021, 'type': 'input', 'position': 13}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 14}, {'token': '8', 'token_id': 1022, 'type': 'input', 'position': 15}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 16}, {'token': '9', 'token_id': 1023, 'type': 'input', 'position': 17}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 18}, {'token': '10', 'token_id': 2184, 'type': 'input', 'position': 19}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 20}, {'token': '11', 'token_id': 2340, 'type': 'input', 'position': 21}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 22}, {'token': '12', 'token_id': 2260, 'type': 'input', 'position': 23}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 24}, {'token': '13', 'token_id': 2410, 'type': 'input', 'position': 25}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 26}, {'token': '14', 'token_id': 2403, 'type': 'input', 'position': 27}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 28}, {'token': '15', 'token_id': 2321, 'type': 'input', 'position': 29}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 30}, {'token': '16', 'token_id': 2385, 'type': 'input', 'position': 31}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 32}, {'token': '17', 'token_id': 2459, 'type': 'input', 'position': 33}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 34}, {'token': '18', 'token_id': 2324, 'type': 'input', 'position': 35}, {'token': '[SEP]', 'token_id': 102, 'type': 'input', 'position': 36}], 'factors': [[[0.020982008427381516, 0.005239559803158045, 0.19920556247234344, 0.009425577707588673, 0.21938276290893555, 0.007179679349064827, 0.22364041209220886, 0.004628925584256649, 0.22656498849391937, 0.0004386034270282835, 0.22441497445106506, 0.0015177634777501225, 0.229053795337677, 0.0020646678749471903, 0.2268010973930359, 0.0008863511029630899, 0.22644750773906708, 0.0, 0.2218550145626068, 0.0008685550419613719, 0.22063277661800385, 0.0, 0.22296667098999023, 0.0, 0.22403468191623688, 0.0, 0.2233114242553711, 0.0, 0.22454971075057983, 0.0, 0.2209661900997162, 0.001847345381975174, 0.2209702581167221, 0.0, 0.20277775824069977, 0.0, 0.0], [0.02520962804555893, 0.0016566433478146791, 0.0013826852664351463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00040469507803209126, 0.0, 0.0, 0.0007012863061390817, 0.0, 0.0004369366215541959, 0.0009767148876562715, 0.0016785544576123357, 0.0012188897235319018, 0.0030585983768105507, 0.002170633291825652, 0.0052870181389153, 0.006949595175683498, 1.2559698820114136], [0.025009378790855408, 0.18463866412639618, 0.00255584716796875, 0.2377273291349411, 0.00041796689038164914, 0.2761276960372925, 0.0, 0.2936975359916687, 0.0, 0.3210451900959015, 0.0, 0.30746185779571533, 0.0, 0.33664047718048096, 0.0032585742883384228, 0.32913967967033386, 0.0016852521803230047, 0.3358213007450104, 0.0016112549928948283, 0.3192616403102875, 0.0, 0.3287080228328705, 0.0006185891688801348, 0.33695927262306213, 0.00015980753232724965, 0.341602087020874, 0.0007685599266551435, 0.32356059551239014, 0.00013604044215753675, 0.3102967441082001, 0.0, 0.30199098587036133, 0.0, 0.3119242191314697, 0.001462575513869524, 0.2688206434249878, 0.0]]]},\n            {\n            'hltrCFG': {'tokenization_config': {\"token_prefix\": \"\", \"partial_token_prefix\": \"##\"}\n                }\n            })\n         }, function (err) {\n            console.log(err);\n        })",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18\"\n",
    "inputs = lm.tokenizer([text], return_tensors=\"pt\")\n",
    "output = lm(inputs)\n",
    "nnmf_example1 = output.run_nmf(n_components=3)\n",
    "nnmf_example1.explore()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By hovering over each \"factor\", you can see how each token responded by the specific factor. In the example above, factor 1 seemed to respond to the commas, factor 2 the [SEP] token and factor 3 to the numbers of the simple sequence.\n",
    "But what if this explaining step could be automatized?\n",
    "I tried using openai's large language models for this - an example can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' commas with varying levels of activation.',\n",
       " ' the [SEP] token at the end of the sequence.',\n",
       " ' incrementing numbers.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnmf_example1.explain()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nnmf provides a value for how much each tokes relates to the each factor - this value is used by ECCO to colour the tokens above.\n",
    "I normalized the these values into values between 0 and 10, and provided this information to the model in the format:\n",
    "\n",
    "\"Activations:\n",
    "\n",
    "token1 \t0\n",
    "\n",
    "token2\t5\n",
    "\n",
    "token3\t8\n",
    "\n",
    "Same activations but with zeros removed:\n",
    " \n",
    "token2\t5\n",
    "\n",
    "token3\t8\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of .explain() method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explain method mainly uses 2 techniques to guide/ground the model in making the summaries!\n",
    "The first method is known as in-context learning (Dong et, al. 2022) - providing the model with a few examples of what you want it to do (and how to respond if it can't)!\n",
    "In the \"promp.py\" file, I've written the prompt used by the explain method. \n",
    "However, I quickly ran into trouble, since I wanted the model to have examples of different types of input.\n",
    "I wanted it to provide appropriate summaries of snippets of code, as well as poems.\n",
    "For this reason I quickly ran out of space, since the maximum context-length of the model I was using was 4097!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common way of adressing this issue is by employing the second technique: indexing.\n",
    "By embedding each of my example prompts + explanations in a vector space I am able to pull the most similiar examples (those closest in this embedded vector space), and use these specific examples to ground the model.\n",
    "This way, It's possible to have a large amount of highly specific instructions, from which the model can extract the most relevant information.\n",
    "I manually analyzed some examples, embedded them using openai's embedding model: \"text-embedding-ada-002\", and wrote a customized search class (in embedding_searcher.py) which found the most relevant examples, and wrote a method to add the examples, until no more could fit in the prompt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, this is how .explain() (sort of) works - by creating some additional \"factual\" information that the LLM can use, as well as a way of \"choosing\" from this pool of specialized knowledge.\n",
    "Using this specialized knowledge in combination with its huge background training - I hoped to automatize a bit of explainability, without having to fine-tune!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .explain() yourself!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, I'll let GPT-3.5 analyze this short poem written by GPT-3.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem = \"\"\"\n",
    "A robot small yet smart and bright,\n",
    "With features that delight the sight,\n",
    "Anki Vector's the name to know,\n",
    "A friend that's more than just a show.\n",
    "\n",
    "He rolls around and scans the room,\n",
    "With sensors that dispel the gloom,\n",
    "He recognizes faces and can hear,\n",
    "Your voice and commands he holds dear.\n",
    "\n",
    "A charming bot that loves to play,\n",
    "And keep you company all day,\n",
    "Anki Vector, oh how we adore,\n",
    "A companion we can't ignore. \n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this poem is much more complex than the counting sequence, let's just look at only the final layer, and let's assume that more components might be appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html lang=\"en\">\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "    var ecco_url = 'https://storage.googleapis.com/ml-intro/ecco/'\n",
       "    //var ecco_url = 'http://localhost:8000/'\n",
       "\n",
       "    if (window.ecco === undefined) window.ecco = {}\n",
       "\n",
       "    // Setup the paths of the script we'll be using\n",
       "    requirejs.config({\n",
       "        urlArgs: \"bust=\" + (new Date()).getTime(),\n",
       "        nodeRequire: require,\n",
       "        paths: {\n",
       "            d3: \"https://d3js.org/d3.v6.min\", // This is only for use in setup.html and basic.html\n",
       "            \"d3-array\": \"https://d3js.org/d3-array.v2.min\",\n",
       "            jquery: \"https://code.jquery.com/jquery-3.5.1.min\",\n",
       "            ecco: ecco_url + 'js/0.0.6/ecco-bundle.min',\n",
       "            xregexp: 'https://cdnjs.cloudflare.com/ajax/libs/xregexp/3.2.0/xregexp-all.min'\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Add the css file\n",
       "    //requirejs(['d3'],\n",
       "    //    function (d3) {\n",
       "    //        d3.select('#css').attr('href', ecco_url + 'html/styles.css')\n",
       "    //    })\n",
       "\n",
       "    console.log('Ecco initialize!!')\n",
       "\n",
       "    // returns a 'basic' object. basic.init() selects the html div we'll be\n",
       "    // rendering the html into, adds styles.css to the document.\n",
       "    define('basic', ['d3'],\n",
       "        function (d3) {\n",
       "            return {\n",
       "                init: function (viz_id = null) {\n",
       "                    if (viz_id == null) {\n",
       "                        viz_id = \"viz_\" + Math.round(Math.random() * 10000000)\n",
       "                    }\n",
       "                    // Select the div rendered below, change its id\n",
       "                    const div = d3.select('#basic').attr('id', viz_id),\n",
       "                        div_parent = d3.select('#' + viz_id).node().parentNode\n",
       "\n",
       "                    // Link to CSS file\n",
       "                    d3.select(div_parent).insert('link')\n",
       "                        .attr('rel', 'stylesheet')\n",
       "                        .attr('type', 'text/css')\n",
       "                        .attr('href', ecco_url + 'html/0.0.2/styles.css')\n",
       "\n",
       "                    return viz_id\n",
       "                }\n",
       "            }\n",
       "        }, function (err) {\n",
       "            console.log(err);\n",
       "        }\n",
       "    )\n",
       "</script>\n",
       "\n",
       "<head>\n",
       "    <link id='css' rel=\"stylesheet\" type=\"text/css\">\n",
       "</head>\n",
       "<div id=\"basic\"></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n         requirejs(['basic', 'ecco'], function(basic, ecco){\n            const viz_id = basic.init()\n            \n            ecco.interactiveTokensAndFactorSparklines(viz_id, {'tokens': [{'token': '[CLS]', 'token_id': 101, 'type': 'input', 'position': 0}, {'token': 'a', 'token_id': 1037, 'type': 'input', 'position': 1}, {'token': 'robot', 'token_id': 8957, 'type': 'input', 'position': 2}, {'token': 'small', 'token_id': 2235, 'type': 'input', 'position': 3}, {'token': 'yet', 'token_id': 2664, 'type': 'input', 'position': 4}, {'token': 'smart', 'token_id': 6047, 'type': 'input', 'position': 5}, {'token': 'and', 'token_id': 1998, 'type': 'input', 'position': 6}, {'token': 'bright', 'token_id': 4408, 'type': 'input', 'position': 7}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 8}, {'token': 'with', 'token_id': 2007, 'type': 'input', 'position': 9}, {'token': 'features', 'token_id': 2838, 'type': 'input', 'position': 10}, {'token': 'that', 'token_id': 2008, 'type': 'input', 'position': 11}, {'token': 'delight', 'token_id': 12208, 'type': 'input', 'position': 12}, {'token': 'the', 'token_id': 1996, 'type': 'input', 'position': 13}, {'token': 'sight', 'token_id': 4356, 'type': 'input', 'position': 14}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 15}, {'token': 'an', 'token_id': 2019, 'type': 'input', 'position': 16}, {'token': '##ki', 'token_id': 3211, 'type': 'input', 'position': 17}, {'token': 'vector', 'token_id': 9207, 'type': 'input', 'position': 18}, {'token': \"'\", 'token_id': 1005, 'type': 'input', 'position': 19}, {'token': 's', 'token_id': 1055, 'type': 'input', 'position': 20}, {'token': 'the', 'token_id': 1996, 'type': 'input', 'position': 21}, {'token': 'name', 'token_id': 2171, 'type': 'input', 'position': 22}, {'token': 'to', 'token_id': 2000, 'type': 'input', 'position': 23}, {'token': 'know', 'token_id': 2113, 'type': 'input', 'position': 24}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 25}, {'token': 'a', 'token_id': 1037, 'type': 'input', 'position': 26}, {'token': 'friend', 'token_id': 2767, 'type': 'input', 'position': 27}, {'token': 'that', 'token_id': 2008, 'type': 'input', 'position': 28}, {'token': \"'\", 'token_id': 1005, 'type': 'input', 'position': 29}, {'token': 's', 'token_id': 1055, 'type': 'input', 'position': 30}, {'token': 'more', 'token_id': 2062, 'type': 'input', 'position': 31}, {'token': 'than', 'token_id': 2084, 'type': 'input', 'position': 32}, {'token': 'just', 'token_id': 2074, 'type': 'input', 'position': 33}, {'token': 'a', 'token_id': 1037, 'type': 'input', 'position': 34}, {'token': 'show', 'token_id': 2265, 'type': 'input', 'position': 35}, {'token': '.', 'token_id': 1012, 'type': 'input', 'position': 36}, {'token': 'he', 'token_id': 2002, 'type': 'input', 'position': 37}, {'token': 'rolls', 'token_id': 9372, 'type': 'input', 'position': 38}, {'token': 'around', 'token_id': 2105, 'type': 'input', 'position': 39}, {'token': 'and', 'token_id': 1998, 'type': 'input', 'position': 40}, {'token': 'scans', 'token_id': 27404, 'type': 'input', 'position': 41}, {'token': 'the', 'token_id': 1996, 'type': 'input', 'position': 42}, {'token': 'room', 'token_id': 2282, 'type': 'input', 'position': 43}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 44}, {'token': 'with', 'token_id': 2007, 'type': 'input', 'position': 45}, {'token': 'sensors', 'token_id': 13907, 'type': 'input', 'position': 46}, {'token': 'that', 'token_id': 2008, 'type': 'input', 'position': 47}, {'token': 'di', 'token_id': 4487, 'type': 'input', 'position': 48}, {'token': '##sp', 'token_id': 13102, 'type': 'input', 'position': 49}, {'token': '##el', 'token_id': 2884, 'type': 'input', 'position': 50}, {'token': 'the', 'token_id': 1996, 'type': 'input', 'position': 51}, {'token': 'gloom', 'token_id': 24067, 'type': 'input', 'position': 52}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 53}, {'token': 'he', 'token_id': 2002, 'type': 'input', 'position': 54}, {'token': 'recognizes', 'token_id': 14600, 'type': 'input', 'position': 55}, {'token': 'faces', 'token_id': 5344, 'type': 'input', 'position': 56}, {'token': 'and', 'token_id': 1998, 'type': 'input', 'position': 57}, {'token': 'can', 'token_id': 2064, 'type': 'input', 'position': 58}, {'token': 'hear', 'token_id': 2963, 'type': 'input', 'position': 59}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 60}, {'token': 'your', 'token_id': 2115, 'type': 'input', 'position': 61}, {'token': 'voice', 'token_id': 2376, 'type': 'input', 'position': 62}, {'token': 'and', 'token_id': 1998, 'type': 'input', 'position': 63}, {'token': 'commands', 'token_id': 10954, 'type': 'input', 'position': 64}, {'token': 'he', 'token_id': 2002, 'type': 'input', 'position': 65}, {'token': 'holds', 'token_id': 4324, 'type': 'input', 'position': 66}, {'token': 'dear', 'token_id': 6203, 'type': 'input', 'position': 67}, {'token': '.', 'token_id': 1012, 'type': 'input', 'position': 68}, {'token': 'a', 'token_id': 1037, 'type': 'input', 'position': 69}, {'token': 'charming', 'token_id': 11951, 'type': 'input', 'position': 70}, {'token': 'bot', 'token_id': 28516, 'type': 'input', 'position': 71}, {'token': 'that', 'token_id': 2008, 'type': 'input', 'position': 72}, {'token': 'loves', 'token_id': 7459, 'type': 'input', 'position': 73}, {'token': 'to', 'token_id': 2000, 'type': 'input', 'position': 74}, {'token': 'play', 'token_id': 2377, 'type': 'input', 'position': 75}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 76}, {'token': 'and', 'token_id': 1998, 'type': 'input', 'position': 77}, {'token': 'keep', 'token_id': 2562, 'type': 'input', 'position': 78}, {'token': 'you', 'token_id': 2017, 'type': 'input', 'position': 79}, {'token': 'company', 'token_id': 2194, 'type': 'input', 'position': 80}, {'token': 'all', 'token_id': 2035, 'type': 'input', 'position': 81}, {'token': 'day', 'token_id': 2154, 'type': 'input', 'position': 82}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 83}, {'token': 'an', 'token_id': 2019, 'type': 'input', 'position': 84}, {'token': '##ki', 'token_id': 3211, 'type': 'input', 'position': 85}, {'token': 'vector', 'token_id': 9207, 'type': 'input', 'position': 86}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 87}, {'token': 'oh', 'token_id': 2821, 'type': 'input', 'position': 88}, {'token': 'how', 'token_id': 2129, 'type': 'input', 'position': 89}, {'token': 'we', 'token_id': 2057, 'type': 'input', 'position': 90}, {'token': 'ad', 'token_id': 4748, 'type': 'input', 'position': 91}, {'token': '##ore', 'token_id': 5686, 'type': 'input', 'position': 92}, {'token': ',', 'token_id': 1010, 'type': 'input', 'position': 93}, {'token': 'a', 'token_id': 1037, 'type': 'input', 'position': 94}, {'token': 'companion', 'token_id': 7452, 'type': 'input', 'position': 95}, {'token': 'we', 'token_id': 2057, 'type': 'input', 'position': 96}, {'token': 'can', 'token_id': 2064, 'type': 'input', 'position': 97}, {'token': \"'\", 'token_id': 1005, 'type': 'input', 'position': 98}, {'token': 't', 'token_id': 1056, 'type': 'input', 'position': 99}, {'token': 'ignore', 'token_id': 8568, 'type': 'input', 'position': 100}, {'token': '.', 'token_id': 1012, 'type': 'input', 'position': 101}, {'token': '[SEP]', 'token_id': 102, 'type': 'input', 'position': 102}], 'factors': [[[0.0, 0.015990210697054863, 0.003948667086660862, 0.0006048290524631739, 0.0, 0.0, 0.0, 0.0, 0.0011909703025594354, 0.0, 0.0023244726471602917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007888298481702805, 0.0, 0.0, 0.0, 0.0, 0.009735314175486565, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4418354034423828, 0.0, 0.009475591592490673, 0.0, 8.251937833847478e-05, 0.0, 0.012628788128495216, 1.2648695707321167, 0.0, 0.0, 0.031122101470828056, 0.010614649392664433, 0.00316077983006835, 0.0, 0.0, 0.007328385021537542, 0.0, 0.02001275308430195, 0.0, 0.009333840571343899, 0.03319118544459343, 0.0, 0.0, 0.0035786819644272327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0025767344050109386, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0034262104891240597, 0.01045676413923502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004971765447407961, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0039029077161103487, 0.0007883670041337609, 0.0, 0.0, 0.0, 0.003862854791805148, 0.025398869067430496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.2337632179260254, 0.020435050129890442, 0.0, 0.0, 0.967679500579834], [0.0, 0.06205334886908531, 0.0, 0.0, 0.14856931567192078, 0.0, 1.0799800157546997, 0.0014785598032176495, 0.15700313448905945, 0.3197747766971588, 0.0, 0.049406763166189194, 0.0, 0.0, 0.0, 0.0, 0.12036725133657455, 0.0, 0.0, 0.09882774949073792, 0.03253751993179321, 0.0, 0.0006379600963555276, 0.0, 0.0, 0.02548646181821823, 0.09725768119096756, 0.0, 0.052605122327804565, 0.010340426117181778, 0.0, 0.0, 0.0, 0.0, 0.01915169693529606, 0.0, 0.0, 0.09164350479841232, 0.0, 0.02264072373509407, 1.4621742963790894, 0.0, 0.0, 0.0, 0.02080293744802475, 0.12094859033823013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004049995914101601, 0.16684246063232422, 0.0, 0.0, 1.2315746545791626, 0.09831137210130692, 0.0029701427556574345, 0.0, 0.09361650049686432, 0.0017835323233157396, 1.0268477201461792, 0.0, 0.1565016806125641, 0.0, 0.0055939871817827225, 0.11692318320274353, 0.1185520589351654, 0.0, 0.0, 0.1286463886499405, 0.0, 0.006041774060577154, 0.0, 0.0, 1.0962002277374268, 0.0, 0.02331911399960518, 0.0, 0.04041707515716553, 0.02364686317741871, 0.0, 0.13585850596427917, 0.0, 0.0, 0.009232119657099247, 0.07072869688272476, 0.024350883439183235, 0.0, 0.04924331232905388, 0.0, 0.0, 0.10025185346603394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.022464871406555176, 0.0, 0.003749336814507842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002402957295998931, 0.01677454076707363, 0.007701600901782513, 0.0, 0.0, 0.019571196287870407, 0.018652936443686485, 0.0, 0.005595996510237455, 0.0, 0.0, 0.0, 0.0019795941188931465, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010074515827000141, 0.0036946325562894344, 0.0008909230236895382, 0.09930752962827682, 0.018120460212230682, 0.0, 0.007964391261339188, 0.0025183572433888912, 0.0, 0.0, 0.002345756161957979, 0.00841191504150629, 0.006147054955363274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009482604451477528, 0.017448483034968376, 0.0, 0.004738166928291321, 0.0, 0.010843341238796711, 0.0005300897173583508, 0.0, 0.00665243761613965, 0.0026057218201458454, 0.004406589083373547, 0.0, 0.027058353647589684, 0.0, 0.0023165270686149597, 0.4930993318557739, 0.03100469335913658, 0.0, 0.0, 0.01880776882171631, 0.0, 0.004437138792127371, 0.008861910551786423, 0.0, 0.0, 0.0, 0.022874759510159492, 0.0024231725838035345, 0.0, 0.03113148733973503, 0.017659062519669533, 0.014605586417019367, 0.0016862594056874514, 0.0, 0.0, 0.03648005425930023, 0.004673972260206938, 0.02144014835357666, 0.0, 0.0, 0.0, 0.012493315152823925, 0.0, 0.028755415230989456, 0.0, 0.0, 0.007547770161181688, 0.0, 1.3481193780899048, 0.054477907717227936], [0.0, 0.01913461834192276, 0.013443534262478352, 0.030868178233504295, 0.03026002272963524, 0.03183712437748909, 0.012020261958241463, 0.019028853625059128, 0.006647428963333368, 0.024156752973794937, 0.021835433319211006, 0.0, 0.007989407517015934, 0.005027017090469599, 0.010298504494130611, 0.0, 0.02706877514719963, 0.04171939939260483, 0.01771116442978382, 0.0026143952272832394, 0.015040659345686436, 0.0, 0.016108421608805656, 0.0, 0.03281619772315025, 0.0031595162581652403, 0.021100683137774467, 0.010077428072690964, 0.017053214833140373, 0.0, 0.012175561860203743, 0.03706282004714012, 0.03920794650912285, 0.02887018397450447, 0.023722859099507332, 0.012712568044662476, 0.0, 0.027297768741846085, 0.01397104561328888, 0.029243724420666695, 0.005173268262296915, 0.02012697607278824, 0.02089347317814827, 0.02714553289115429, 0.0051489900797605515, 0.020426679402589798, 0.02330254763364792, 0.007431134581565857, 0.03964897245168686, 0.04287488013505936, 0.0455208495259285, 0.018995732069015503, 0.013911046087741852, 0.0, 0.019984038546681404, 0.012295139022171497, 0.01750321127474308, 0.0052026440389454365, 0.021269021555781364, 0.03031725063920021, 0.00241689826361835, 0.019961554557085037, 0.022402923554182053, 0.0, 0.019117126241326332, 0.021269693970680237, 0.017544645816087723, 0.024734264239668846, 0.011748099699616432, 0.027942925691604614, 0.017165547236800194, 0.017673606052994728, 0.02298779971897602, 0.020996149629354477, 0.019995607435703278, 0.02464018017053604, 0.0, 0.0, 0.0394601970911026, 0.02547360211610794, 0.02295033447444439, 0.03636105731129646, 0.027013076469302177, 0.019124774262309074, 0.030838578939437866, 0.04245499521493912, 0.02087639831006527, 0.003426630748435855, 0.021540800109505653, 0.036578115075826645, 0.028098512440919876, 0.04472271353006363, 0.030832964926958084, 0.006059703882783651, 0.029433295130729675, 0.01690429449081421, 0.03628673404455185, 0.033835891634225845, 0.0, 0.0352829173207283, 0.024655897170305252, 0.0, 0.016605347394943237], [0.03967660665512085, 0.006205448415130377, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0037548320833593607, 0.0, 0.003330752020701766, 0.029458319768309593, 0.0018236692994832993, 0.0, 0.002971953246742487, 0.0, 0.0, 0.0, 0.10036938637495041, 0.08972907066345215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0025203318800777197, 0.1032685935497284, 0.10949962586164474, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014018883928656578, 0.07308672368526459, 0.002252305159345269, 0.009618976153433323, 0.08565716445446014, 0.0035243297461420298, 0.0, 0.005635383538901806, 0.0, 0.0, 0.0, 0.003737402381375432, 0.0, 0.0080111650750041, 0.0027832137420773506, 0.0, 0.005984523333609104, 0.018577614799141884, 0.07923908531665802, 0.0, 0.002118397504091263, 0.059179387986660004, 0.0009468842181377113, 0.0, 0.002977128839120269, 0.0, 0.0, 0.0010983101092278957, 0.005555534269660711, 0.06428805738687515, 0.0, 0.0, 0.005361716728657484, 0.0, 0.0, 0.0, 0.06529033184051514, 0.0, 0.00020266656065359712, 0.0, 0.0, 0.011118541471660137, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008286898024380207, 0.0, 0.0, 0.0052489894442260265, 0.003149621421471238, 0.011652248911559582, 0.0, 0.0, 0.0, 0.006908784620463848, 0.04164924845099449, 0.0, 0.012565658427774906, 0.0, 0.0, 0.007922141812741756], [0.0, 0.0, 0.0, 0.0, 0.016317974776029587, 0.0, 0.007431757636368275, 0.0, 0.0, 0.04013771936297417, 0.0, 0.3080810010433197, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011729569174349308, 0.011631043627858162, 0.0, 0.005416505504399538, 0.26361292600631714, 0.001425494090653956, 0.0076063754968345165, 0.009742040187120438, 0.0, 0.15864819288253784, 0.0, 0.024974606931209564, 0.04588127136230469, 0.068926140666008, 0.017247412353754044, 0.011395648121833801, 0.0, 0.0, 0.0007162250112742186, 0.0, 0.0075724381022155285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004842626862227917, 0.0, 0.3031102418899536, 0.0, 0.0020326157100498676, 0.0, 0.0, 0.0, 0.0014052542392164469, 0.003907837904989719, 0.0, 0.0, 0.013777310959994793, 0.022514209151268005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013229948468506336, 0.0, 0.0, 0.018057893961668015, 0.017637763172388077, 0.0, 0.0, 0.18244637548923492, 0.0, 0.1541827768087387, 0.0, 0.0, 0.011628279462456703, 0.0, 0.001851016073487699, 0.0, 0.018856380134820938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0025744561571627855, 0.032769136130809784, 0.0, 0.0, 0.0, 0.005794320721179247, 0.011178127489984035, 0.0, 0.015117920935153961, 0.035687923431396484, 0.0, 0.05242253467440605, 0.0, 0.0, 0.0], [0.0, 0.004062680993229151, 0.0024759764783084393, 0.003384573385119438, 0.010909979231655598, 0.0, 0.003054267494007945, 0.002756038447842002, 0.36014312505722046, 0.0010884720832109451, 0.0, 0.0, 0.0, 0.0, 0.0006901168962940574, 0.34777817130088806, 0.0, 0.0, 0.0, 0.011303483508527279, 0.0036670302506536245, 0.0, 0.005333989392966032, 0.0, 0.0036530736833810806, 0.38457533717155457, 0.005745680537074804, 0.0, 0.006485061254352331, 0.11503275483846664, 0.003195910481736064, 0.008446820080280304, 0.010453606955707073, 0.008881313726305962, 0.004777172114700079, 0.0016431666444987059, 0.0, 0.0009936320129781961, 0.0, 0.008824131451547146, 3.0051605790504254e-05, 0.0, 0.0, 0.0, 0.31260669231414795, 0.00740837911143899, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001629601581953466, 0.000303182314382866, 0.33406639099121094, 0.0022541522048413754, 0.0, 0.0034947337117046118, 0.0, 0.0, 0.0, 0.28212714195251465, 8.068830356933177e-05, 0.0, 0.0, 0.0, 0.004171461332589388, 0.0, 0.0020794959273189306, 0.027793243527412415, 0.0025487011298537254, 0.0, 0.0009122687624767423, 0.005645556375384331, 0.0, 0.0, 0.0010777526767924428, 0.3511420786380768, 0.0, 0.0, 0.00936997402459383, 0.0026915057096630335, 0.0, 0.005316395778208971, 0.247893288731575, 0.0, 0.0, 0.001513872528448701, 0.2707015872001648, 0.0037259580567479134, 0.002234702231362462, 0.0026054084300994873, 0.0, 0.0, 0.3348053991794586, 0.003973963670432568, 0.0016709326300770044, 0.0009068427607417107, 0.0, 0.024631274864077568, 0.0, 0.0, 0.0, 0.07158771902322769], [0.0, 0.07330832630395889, 0.008223777636885643, 0.003496129997074604, 0.0, 0.0, 0.0, 0.004703442566096783, 0.0, 0.023495931178331375, 0.0, 0.015067403204739094, 0.0, 0.3327624499797821, 0.0084940604865551, 0.0, 0.07936055958271027, 0.0, 0.0, 0.09735408425331116, 0.02281765267252922, 0.526340663433075, 0.016848430037498474, 0.027875201776623726, 0.0, 0.0, 0.07609795033931732, 0.004200668074190617, 0.0988745391368866, 0.1790212094783783, 0.023685120046138763, 0.05982010066509247, 0.06413159519433975, 0.05297292768955231, 0.04926368594169617, 0.003771024290472269, 0.0, 0.06165222451090813, 0.0, 0.019031565636396408, 0.010593005456030369, 0.0, 0.3871825635433197, 0.02833562344312668, 0.014542938210070133, 0.025558214634656906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2421746551990509, 0.006752719637006521, 0.0030403612181544304, 0.04571262001991272, 0.0, 0.0022088289260864258, 0.0, 0.0, 0.0, 0.0, 0.02261902205646038, 0.0004861618799623102, 0.0, 0.0, 0.053323958069086075, 0.0, 0.0, 0.04528136923909187, 0.03949974477291107, 0.0, 0.0, 0.059349577873945236, 0.0, 0.0815478041768074, 0.009437563829123974, 0.0, 0.0, 0.0, 0.050166722387075424, 0.011466524563729763, 0.2052050679922104, 0.06427788734436035, 0.007162279915064573, 0.08425618708133698, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044936321675777435, 0.0, 0.0, 0.0, 0.061313606798648834, 0.0, 0.030921000987291336, 0.0, 0.035323575139045715, 0.0, 0.0, 0.0, 0.06367973238229752]]]},\n            {\n            'hltrCFG': {'tokenization_config': {\"token_prefix\": \"\", \"partial_token_prefix\": \"##\"}\n                }\n            })\n         }, function (err) {\n            console.log(err);\n        })",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = lm.tokenizer([poem], return_tensors=\"pt\")\n",
    "output = lm(inputs)\n",
    "nnmf_example2 = output.run_nmf(n_components=8, from_layer=5, to_layer=6)\n",
    "nnmf_example2.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' punctuation marks, particularly quotation marks and periods, as well as the [SEP] token.',\n",
       " ' a combination of tokens such as \"yet\", \"with\", \"he\", \"and\" to identify certain patterns in the input.',\n",
       " ' punctuation marks (periods).',\n",
       " ' words and phrases that refer to a robotic companion that is small, smart, and bright with features that delight the sight, that rolls around and scans the room, recognizing faces and hearing commands, and that loves to play and keep you company.',\n",
       " \" specific tokens that refer to a robot, such as 'an ##ki vector', 'he rolls', 'he scans', 'he recognizes', 'can hear', 'loves to play', 'keep you company', and 'can't ignore'.\",\n",
       " \" specific tokens such as 'that', 'to', 'more', 'can', and 't' in the context of the document.\",\n",
       " ' punctuation and contractions in the sentence.',\n",
       " ' words related to a robotic friend.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnmf_example2.explain()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fourth, and eight factor are overly broad.\n",
    "Similiarly it would be great if the fifth factor would correctly be recognized as responding to verbs.\n",
    "It seems to appropriately identify factors responding to different types of punctuation - probably since these examples are well-represented in the examples.\n",
    "These results are not great, but the project was interesting! More examples would certainly help guide it. And since I wrote the method in a way, which just adds examples, untill there are no more tokens left this technique should scale well to a larger database of examples, as well as a model with more context length.\n",
    "I think it serves well as a proof of concept, and the idea of using LLMs to analyse LLMS is super exciting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements (TODO's)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course these result could be improved! \n",
    "Some low-hanging fruits are:\n",
    "- More (and higher quality) explanation examples.\n",
    "- A more complex masking-threshold selection (right now, the masking does not take into account, that tokens above the threshold don't all have identical values)\n",
    "- Access to models with longer context-length (GPT-4 has double the context length!)\n",
    "- Exploration of different indexing/search methods like lexical or graph-based approaches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Dong, Q., Li, L., Dai, D., Zheng, C., Wu, Z., Chang, B., ... & Sui, Z. (2022). A Survey for In-context Learning. arXiv preprint arXiv:2301.00234."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
