{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 20 explanation strings\n",
    "# make sure strings are shorter than some length\n",
    "# Add to list of strings\n",
    "# create embeddings\n",
    "# create dataframe for string + embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Activations: 'Factor 1:\\nActivations\\n<start>\\n[CLS]\\t0\\n1\\t0\\n,\\t2\\n2\\t0\\n,\\t2\\n3\\t0\\n,\\t2\\n4\\t0\\n,\\t2\\n5\\t0\\n,\\t2\\n6\\t0\\n,\\t2\\n7\\t0\\n,\\t2\\n8\\t0\\n,\\t2\\n9\\t0\\n,\\t2\\n10\\t0\\n,\\t2\\n11\\t0\\n,\\t2\\n12\\t0\\n,\\t2\\n13\\t0\\n,\\t2\\n14\\t0\\n,\\t2\\n15\\t0\\n,\\t2\\n16\\t0\\n,\\t2\\n17\\t0\\n,\\t2\\n18\\t0\\n[SEP]\\t0\\n<end>\\nsame_string but with all zeros filtered out:\\n<start>,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n<end>\\n',\n",
    "Explanation of Factor 1: the main thing this factor does is find commas\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Activations: 'Factor 2:\\nActivations\\n<start>\\n[CLS]\\t0\\n1\\t0\\n,\\t0\\n2\\t0\\n,\\t0\\n3\\t0\\n,\\t0\\n4\\t0\\n,\\t0\\n5\\t0\\n,\\t0\\n6\\t0\\n,\\t0\\n7\\t0\\n,\\t0\\n8\\t0\\n,\\t0\\n9\\t0\\n,\\t0\\n10\\t0\\n,\\t0\\n11\\t0\\n,\\t0\\n12\\t0\\n,\\t0\\n13\\t0\\n,\\t0\\n14\\t0\\n,\\t0\\n15\\t0\\n,\\t0\\n16\\t0\\n,\\t0\\n17\\t0\\n,\\t0\\n18\\t0\\n[SEP]\\t10\\n<end>\\nsame_string but with all zeros filtered out:\\n<start>[SEP]\\t10\\n<end>\\n',\n",
    "Explanation of Factor 2: the main thing this factor does is find the [SEP] token, denoting the end of the sentence.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Activations: 'Factor 3:\\nActivations\\n<start>\\n[CLS]\\t0\\n1\\t1\\n,\\t0\\n2\\t2\\n,\\t0\\n3\\t2\\n,\\t0\\n4\\t2\\n,\\t0\\n5\\t3\\n,\\t0\\n6\\t2\\n,\\t0\\n7\\t3\\n,\\t0\\n8\\t3\\n,\\t0\\n9\\t3\\n,\\t0\\n10\\t3\\n,\\t0\\n11\\t3\\n,\\t0\\n12\\t3\\n,\\t0\\n13\\t3\\n,\\t0\\n14\\t3\\n,\\t0\\n15\\t2\\n,\\t0\\n16\\t2\\n,\\t0\\n17\\t2\\n,\\t0\\n18\\t2\\n[SEP]\\t0\\n<end>\\nsame_string but with all zeros filtered out:\\n<start>1\\t1\\n2\\t2\\n3\\t2\\n4\\t2\\n5\\t3\\n6\\t2\\n7\\t3\\n8\\t3\\n9\\t3\\n10\\t3\\n11\\t3\\n12\\t3\\n13\\t3\\n14\\t3\\n15\\t2\\n16\\t2\\n17\\t2\\n18\\t2\\n<end>\\n']\n",
    "Explanation of Factor 3: the main thing this factor does is find incrementing numbers\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Activations: 'Factor 1:\\nActivations\\n<start>\\n\\n[CLS]\\t0\\n1\\t0\\n,\\t0\\n2\\t0\\n,\\t0\\n3\\t0\\n,\\t0\\n4\\t0\\n,\\t0\\n5\\t0\\n,\\t0\\n6\\t0\\n,\\t0\\n7\\t0\\n,\\t0\\n8\\t0\\n,\\t0\\n9\\t0\\n,\\t0\\n10\\t1\\n,\\t0\\n11\\t1\\n,\\t0\\n12\\t1\\n,\\t0\\n13\\t1\\n,\\t0\\n14\\t1\\n,\\t0\\n15\\t1\\n,\\t0\\n16\\t1\\n,\\t0\\n17\\t1\\n,\\t0\\n18\\t1\\n[SEP]\\t0\\n<end>\\nsame_string but with all zeros filtered out:\\n\\n<start>10\\t1\\n11\\t1\\n12\\t1\\n13\\t1\\n14\\t1\\n15\\t1\\n16\\t1\\n17\\t1\\n18\\t1\\n<end>\\n'\n",
    "Explanation of Factor 1: the main thing this factor does is find incrementing numbers, but only in the second half of the sentence.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Activations: 'Factor 2:\\nActivations\\n<start>\\n\\n[CLS]\\t0\\n1\\t1\\n,\\t0\\n2\\t1\\n,\\t0\\n3\\t1\\n,\\t0\\n4\\t1\\n,\\t0\\n5\\t1\\n,\\t0\\n6\\t1\\n,\\t0\\n7\\t1\\n,\\t0\\n8\\t1\\n,\\t0\\n9\\t0\\n,\\t0\\n10\\t0\\n,\\t0\\n11\\t0\\n,\\t0\\n12\\t0\\n,\\t0\\n13\\t0\\n,\\t0\\n14\\t0\\n,\\t0\\n15\\t0\\n,\\t0\\n16\\t0\\n,\\t0\\n17\\t0\\n,\\t0\\n18\\t0\\n[SEP]\\t0\\n<end>\\nsame_string but with all zeros filtered out:\\n\\n<start>1\\t1\\n2\\t1\\n3\\t1\\n4\\t1\\n5\\t1\\n6\\t1\\n7\\t1\\n8\\t1\\n<end>\\n'\n",
    "Explanation of Factor 2: the main thing this factor does is find incrementing numbers, but only in the first half of the sequence.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 1:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "the\t3\n",
    "sky\t0\n",
    "turned\t0\n",
    "a\t0\n",
    "vibrant\t0\n",
    "shade\t0\n",
    "of\t0\n",
    "orange\t0\n",
    "as\t0\n",
    "the\t3\n",
    "sun\t0\n",
    "began\t0\n",
    "to\t0\n",
    "set\t0\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>the\t3\n",
    "the\t3\n",
    "<end>\n",
    "Explanation of Factor 1: the main thing this factor does is find the word \"the\".\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 2:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "the\t0\n",
    "sky\t0\n",
    "turned\t0\n",
    "a\t0\n",
    "vibrant\t0\n",
    "shade\t0\n",
    "of\t0\n",
    "orange\t0\n",
    "as\t0\n",
    "the\t0\n",
    "sun\t0\n",
    "began\t0\n",
    "to\t0\n",
    "set\t0\n",
    ".\t0\n",
    "[SEP]\t9\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>[SEP]\t9\n",
    "<end>\n",
    "Activations:\n",
    "Explanation of Factor 2: the main thing this factor does is find the [SEP] token at the end of input.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 3:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "the\t0\n",
    "sky\t0\n",
    "turned\t0\n",
    "a\t0\n",
    "vibrant\t0\n",
    "shade\t0\n",
    "of\t0\n",
    "orange\t0\n",
    "as\t0\n",
    "the\t0\n",
    "sun\t0\n",
    "began\t0\n",
    "to\t0\n",
    "set\t0\n",
    ".\t9\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>.\t9\n",
    "<end>\n",
    "Explanation of Factor 3: the main thing this factor does is find a period at the end of the input.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 4:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "the\t0\n",
    "sky\t0\n",
    "turned\t1\n",
    "a\t4\n",
    "vibrant\t0\n",
    "shade\t0\n",
    "of\t4\n",
    "orange\t0\n",
    "as\t0\n",
    "the\t0\n",
    "sun\t0\n",
    "began\t0\n",
    "to\t0\n",
    "set\t0\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>turned\t1\n",
    "a\t4\n",
    "of\t4\n",
    "<end>\n",
    "Explanation of Factor 4: the main thing this factor does is find an articles, a preoposition and a verb referring to the previously mentioned sky.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 5:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t4\n",
    "the\t0\n",
    "sky\t0\n",
    "turned\t0\n",
    "a\t0\n",
    "vibrant\t0\n",
    "shade\t0\n",
    "of\t0\n",
    "orange\t0\n",
    "as\t0\n",
    "the\t0\n",
    "sun\t0\n",
    "began\t0\n",
    "to\t0\n",
    "set\t0\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>[CLS]\t4\n",
    "<end>\n",
    "Explanation of Factor 5: the main thing this factor does is find the [CLS] token at the start of the sentence.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 6:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "the\t0\n",
    "sky\t0\n",
    "turned\t0\n",
    "a\t0\n",
    "vibrant\t0\n",
    "shade\t0\n",
    "of\t0\n",
    "orange\t0\n",
    "as\t10\n",
    "the\t0\n",
    "sun\t0\n",
    "began\t0\n",
    "to\t0\n",
    "set\t0\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>as\t10\n",
    "<end>\n",
    "Explanation of Factor 6: the main thing this factor does is find the word as, when used as a conjuction.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 7:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "the\t0\n",
    "sky\t1\n",
    "turned\t0\n",
    "a\t0\n",
    "vibrant\t0\n",
    "shade\t0\n",
    "of\t0\n",
    "orange\t0\n",
    "as\t0\n",
    "the\t0\n",
    "sun\t1\n",
    "began\t0\n",
    "to\t0\n",
    "set\t0\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>sky\t1\n",
    "sun\t1\n",
    "<end>\n",
    "Explanation of Factor 7: the main thing this factor does is find nouns related to the sky.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 8:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "the\t0\n",
    "sky\t0\n",
    "turned\t0\n",
    "a\t0\n",
    "vibrant\t3\n",
    "shade\t2\n",
    "of\t0\n",
    "orange\t3\n",
    "as\t0\n",
    "the\t0\n",
    "sun\t0\n",
    "began\t0\n",
    "to\t0\n",
    "set\t0\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>vibrant\t3\n",
    "shade\t2\n",
    "orange\t3\n",
    "<end>\n",
    "\n",
    "Explanation of Factor 8: the main thing this factor does is find words related to colour\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 9:\n",
    "Activations\n",
    "<start>\n",
    "[CLS]\t0\n",
    "the\t0\n",
    "sky\t0\n",
    "turned\t4\n",
    "a\t0\n",
    "vibrant\t0\n",
    "shade\t0\n",
    "of\t0\n",
    "orange\t0\n",
    "as\t0\n",
    "the\t0\n",
    "sun\t0\n",
    "began\t9\n",
    "to\t0\n",
    "set\t1\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>turned\t4\n",
    "began\t9\n",
    "set\t1\n",
    "<end>\n",
    "\n",
    "Explanation of Factor 9: the main thing this factor does is find verbs related to the sunset.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 10:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "the\t0\n",
    "sky\t0\n",
    "turned\t0\n",
    "a\t0\n",
    "vibrant\t0\n",
    "shade\t0\n",
    "of\t0\n",
    "orange\t0\n",
    "as\t0\n",
    "the\t0\n",
    "sun\t0\n",
    "began\t0\n",
    "to\t3\n",
    "set\t2\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>to\t3\n",
    "set\t2\n",
    "<end>\n",
    "\n",
    "Explanation of Factor 10: the main thing this factor does is find related to the sunset.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 1:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "a\t0\n",
    "gentle\t0\n",
    "breeze\t0\n",
    "whispered\t0\n",
    "through\t0\n",
    "the\t0\n",
    "trees\t0\n",
    ",\t0\n",
    "rustling\t0\n",
    "the\t0\n",
    "leaves\t0\n",
    ".\t5\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>.\t5\n",
    "<end>\n",
    "\n",
    "Explanation of Factor 1: the main thing this factor does is find periods.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 2:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "a\t0\n",
    "gentle\t0\n",
    "breeze\t0\n",
    "whispered\t0\n",
    "through\t0\n",
    "the\t0\n",
    "trees\t0\n",
    ",\t0\n",
    "rustling\t0\n",
    "the\t0\n",
    "leaves\t0\n",
    ".\t0\n",
    "[SEP]\t10\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>[SEP]\t10\n",
    "<end>\n",
    "\n",
    "Explanation of Factor 2: the main thing this factor does is find the [SEP] token at the end of the sequence.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 3:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "a\t0\n",
    "gentle\t0\n",
    "breeze\t1\n",
    "whispered\t0\n",
    "through\t0\n",
    "the\t0\n",
    "trees\t4\n",
    ",\t0\n",
    "rustling\t0\n",
    "the\t0\n",
    "leaves\t4\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>breeze\t1\n",
    "trees\t4\n",
    "leaves\t4\n",
    "<end>\n",
    "Explanation of Factor 1: the main thing this factor does is find words related to trees and wind.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "\n",
    "Factor 4:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "a\t0\n",
    "gentle\t1\n",
    "breeze\t1\n",
    "whispered\t2\n",
    "through\t2\n",
    "the\t0\n",
    "trees\t0\n",
    ",\t0\n",
    "rustling\t1\n",
    "the\t0\n",
    "leaves\t0\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>gentle\t1\n",
    "breeze\t1\n",
    "whispered\t2\n",
    "through\t2\n",
    "rustling\t1\n",
    "<end>\n",
    "Explanation of Factor 1: the main thing this factor does is find words related to a wind in the trees.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## not super clear what the relationship is - maybe the sentence is too short, or the factors too few\n",
    "#explanation = \"\"\"\n",
    "#Factor 5:\n",
    "#Activations\n",
    "#<start>\n",
    "#\n",
    "#[CLS]\t1\n",
    "#a\t3\n",
    "#gentle\t0\n",
    "#breeze\t0\n",
    "#whispered\t0\n",
    "#through\t0\n",
    "#the\t7\n",
    "#trees\t0\n",
    "#,\t3\n",
    "#rustling\t0\n",
    "#the\t7\n",
    "#leaves\t0\n",
    "#.\t0\n",
    "#[SEP]\t0\n",
    "#<end>\n",
    "#same_string but with all zeros filtered out:\n",
    "#\n",
    "#<start>[CLS]\t1\n",
    "#a\t3\n",
    "#the\t7\n",
    "#,\t3\n",
    "#the\t7\n",
    "#<end>\n",
    "#\n",
    "#Explanation of Factor 5: the main thing this factor does is find the word \"the\". \n",
    "#\"\"\"\n",
    "#explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 1:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "as\t0\n",
    "the\t0\n",
    "sun\t0\n",
    "slowly\t0\n",
    "descended\t0\n",
    "below\t0\n",
    "the\t0\n",
    "horizon\t0\n",
    ",\t2\n",
    "casting\t0\n",
    "a\t0\n",
    "warm\t0\n",
    "golden\t0\n",
    "hue\t0\n",
    "across\t0\n",
    "the\t0\n",
    "vast\t0\n",
    "expanse\t0\n",
    "of\t0\n",
    "the\t0\n",
    "sky\t0\n",
    ",\t2\n",
    "the\t0\n",
    "clouds\t0\n",
    "transformed\t0\n",
    "into\t0\n",
    "a\t0\n",
    "me\t0\n",
    "##sm\t0\n",
    "##eri\t0\n",
    "##zing\t0\n",
    "canvas\t0\n",
    "of\t0\n",
    "vibrant\t0\n",
    "orange\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "pink\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "and\t0\n",
    "purple\t0\n",
    "##s\t0\n",
    ",\t2\n",
    "painting\t0\n",
    "a\t0\n",
    "breath\t0\n",
    "##taking\t0\n",
    "masterpiece\t0\n",
    "of\t0\n",
    "nature\t0\n",
    "'\t0\n",
    "s\t0\n",
    "artistic\t0\n",
    "prowess\t0\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>,\t2\n",
    ",\t2\n",
    ",\t2\n",
    "<end>\n",
    "Explanation of Factor 1: the main thing this factor does is find punctuation marks, particularly commas, in the sentence.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 3:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "as\t0\n",
    "the\t0\n",
    "sun\t0\n",
    "slowly\t0\n",
    "descended\t0\n",
    "below\t0\n",
    "the\t0\n",
    "horizon\t0\n",
    ",\t0\n",
    "casting\t0\n",
    "a\t0\n",
    "warm\t0\n",
    "golden\t0\n",
    "hue\t0\n",
    "across\t0\n",
    "the\t0\n",
    "vast\t0\n",
    "expanse\t0\n",
    "of\t0\n",
    "the\t0\n",
    "sky\t0\n",
    ",\t3\n",
    "the\t0\n",
    "clouds\t0\n",
    "transformed\t0\n",
    "into\t0\n",
    "a\t0\n",
    "me\t0\n",
    "##sm\t0\n",
    "##eri\t0\n",
    "##zing\t0\n",
    "canvas\t0\n",
    "of\t0\n",
    "vibrant\t0\n",
    "orange\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "pink\t0\n",
    "##s\t0\n",
    ",\t5\n",
    "and\t0\n",
    "purple\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "painting\t0\n",
    "a\t0\n",
    "breath\t0\n",
    "##taking\t0\n",
    "masterpiece\t0\n",
    "of\t0\n",
    "nature\t0\n",
    "'\t0\n",
    "s\t0\n",
    "artistic\t0\n",
    "prowess\t0\n",
    ".\t7\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>,\t3\n",
    ",\t5\n",
    ".\t7\n",
    "<end>\n",
    "Explanation of Factor 3: the main thing this factor does is find punctuation marks (commas).\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 4:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "as\t0\n",
    "the\t1\n",
    "sun\t0\n",
    "slowly\t0\n",
    "descended\t0\n",
    "below\t0\n",
    "the\t1\n",
    "horizon\t0\n",
    ",\t0\n",
    "casting\t0\n",
    "a\t0\n",
    "warm\t0\n",
    "golden\t0\n",
    "hue\t0\n",
    "across\t0\n",
    "the\t1\n",
    "vast\t0\n",
    "expanse\t0\n",
    "of\t0\n",
    "the\t1\n",
    "sky\t0\n",
    ",\t0\n",
    "the\t1\n",
    "clouds\t0\n",
    "transformed\t0\n",
    "into\t0\n",
    "a\t0\n",
    "me\t0\n",
    "##sm\t0\n",
    "##eri\t0\n",
    "##zing\t0\n",
    "canvas\t0\n",
    "of\t0\n",
    "vibrant\t0\n",
    "orange\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "pink\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "and\t0\n",
    "purple\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "painting\t0\n",
    "a\t0\n",
    "breath\t0\n",
    "##taking\t0\n",
    "masterpiece\t0\n",
    "of\t0\n",
    "nature\t0\n",
    "'\t0\n",
    "s\t0\n",
    "artistic\t0\n",
    "prowess\t0\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>the\t1\n",
    "the\t1\n",
    "the\t1\n",
    "the\t1\n",
    "the\t1\n",
    "<end>\n",
    "Explanation of Factor 4: the main thing this factor does is find the word \"the\".\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 5:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "as\t0\n",
    "the\t0\n",
    "sun\t0\n",
    "slowly\t0\n",
    "descended\t0\n",
    "below\t0\n",
    "the\t0\n",
    "horizon\t0\n",
    ",\t0\n",
    "casting\t0\n",
    "a\t0\n",
    "warm\t0\n",
    "golden\t0\n",
    "hue\t0\n",
    "across\t0\n",
    "the\t0\n",
    "vast\t0\n",
    "expanse\t0\n",
    "of\t0\n",
    "the\t0\n",
    "sky\t0\n",
    ",\t0\n",
    "the\t0\n",
    "clouds\t0\n",
    "transformed\t0\n",
    "into\t0\n",
    "a\t0\n",
    "me\t0\n",
    "##sm\t0\n",
    "##eri\t0\n",
    "##zing\t0\n",
    "canvas\t0\n",
    "of\t0\n",
    "vibrant\t0\n",
    "orange\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "pink\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "and\t0\n",
    "purple\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "painting\t0\n",
    "a\t0\n",
    "breath\t0\n",
    "##taking\t0\n",
    "masterpiece\t0\n",
    "of\t0\n",
    "nature\t0\n",
    "'\t0\n",
    "s\t0\n",
    "artistic\t0\n",
    "prowess\t0\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start><end>\n",
    "Explanation of Factor 5: This factor only returns zero, suggesting that this cluster is very broad, or that it was not activated at all.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 6:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "as\t0\n",
    "the\t0\n",
    "sun\t0\n",
    "slowly\t0\n",
    "descended\t0\n",
    "below\t0\n",
    "the\t0\n",
    "horizon\t0\n",
    ",\t0\n",
    "casting\t0\n",
    "a\t0\n",
    "warm\t0\n",
    "golden\t0\n",
    "hue\t0\n",
    "across\t0\n",
    "the\t0\n",
    "vast\t0\n",
    "expanse\t0\n",
    "of\t0\n",
    "the\t0\n",
    "sky\t0\n",
    ",\t0\n",
    "the\t0\n",
    "clouds\t0\n",
    "transformed\t0\n",
    "into\t0\n",
    "a\t0\n",
    "me\t0\n",
    "##sm\t0\n",
    "##eri\t0\n",
    "##zing\t0\n",
    "canvas\t0\n",
    "of\t0\n",
    "vibrant\t0\n",
    "orange\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "pink\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "and\t0\n",
    "purple\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "painting\t0\n",
    "a\t0\n",
    "breath\t0\n",
    "##taking\t0\n",
    "masterpiece\t0\n",
    "of\t0\n",
    "nature\t0\n",
    "'\t2\n",
    "s\t2\n",
    "artistic\t0\n",
    "prowess\t0\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>'\t2\n",
    "s\t2\n",
    "<end>\n",
    "Explanation of Factor 6: the main thing this factor does is find the tokens ' and s.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "\n",
    "Explanation of Factor:  the [SEP] token, denoting the end of the sentence.\n",
    "Factor 3:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "as\t0\n",
    "the\t0\n",
    "sun\t0\n",
    "slowly\t0\n",
    "descended\t0\n",
    "below\t0\n",
    "the\t0\n",
    "horizon\t0\n",
    ",\t0\n",
    "casting\t0\n",
    "a\t0\n",
    "warm\t0\n",
    "golden\t0\n",
    "hue\t0\n",
    "across\t0\n",
    "the\t0\n",
    "vast\t0\n",
    "expanse\t0\n",
    "of\t0\n",
    "the\t0\n",
    "sky\t0\n",
    ",\t4\n",
    "the\t0\n",
    "clouds\t0\n",
    "transformed\t0\n",
    "into\t0\n",
    "a\t0\n",
    "me\t0\n",
    "##sm\t0\n",
    "##eri\t0\n",
    "##zing\t0\n",
    "canvas\t0\n",
    "of\t0\n",
    "vibrant\t0\n",
    "orange\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "pink\t0\n",
    "##s\t0\n",
    ",\t6\n",
    "and\t0\n",
    "purple\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "painting\t0\n",
    "a\t0\n",
    "breath\t0\n",
    "##taking\t0\n",
    "masterpiece\t0\n",
    "of\t0\n",
    "nature\t0\n",
    "'\t0\n",
    "s\t0\n",
    "artistic\t0\n",
    "prowess\t0\n",
    ".\t10\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>,\t4\n",
    ",\t6\n",
    ".\t10\n",
    "<end>\n",
    "\n",
    "Explanation of Factor 3: The main thing this cluster of neurons does is find punctuation marks. \n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 4:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "as\t0\n",
    "the\t8\n",
    "sun\t0\n",
    "slowly\t0\n",
    "descended\t0\n",
    "below\t0\n",
    "the\t9\n",
    "horizon\t0\n",
    ",\t0\n",
    "casting\t0\n",
    "a\t0\n",
    "warm\t0\n",
    "golden\t0\n",
    "hue\t0\n",
    "across\t0\n",
    "the\t8\n",
    "vast\t1\n",
    "expanse\t0\n",
    "of\t1\n",
    "the\t10\n",
    "sky\t0\n",
    ",\t0\n",
    "the\t7\n",
    "clouds\t0\n",
    "transformed\t0\n",
    "into\t0\n",
    "a\t0\n",
    "me\t0\n",
    "##sm\t0\n",
    "##eri\t0\n",
    "##zing\t0\n",
    "canvas\t0\n",
    "of\t0\n",
    "vibrant\t0\n",
    "orange\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "pink\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "and\t0\n",
    "purple\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "painting\t0\n",
    "a\t0\n",
    "breath\t0\n",
    "##taking\t0\n",
    "masterpiece\t0\n",
    "of\t0\n",
    "nature\t0\n",
    "'\t0\n",
    "s\t0\n",
    "artistic\t0\n",
    "prowess\t0\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>the\t8\n",
    "the\t9\n",
    "the\t8\n",
    "vast\t1\n",
    "of\t1\n",
    "the\t10\n",
    "the\t7\n",
    "<end>\n",
    "Explanation of Factor:  words related to the sunset in a specific context.\n",
    "Factor 5:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t1\n",
    "as\t0\n",
    "the\t0\n",
    "sun\t0\n",
    "slowly\t0\n",
    "descended\t0\n",
    "below\t0\n",
    "the\t0\n",
    "horizon\t0\n",
    ",\t0\n",
    "casting\t4\n",
    "a\t0\n",
    "warm\t3\n",
    "golden\t2\n",
    "hue\t2\n",
    "across\t0\n",
    "the\t0\n",
    "vast\t5\n",
    "expanse\t4\n",
    "of\t0\n",
    "the\t0\n",
    "sky\t0\n",
    ",\t0\n",
    "the\t0\n",
    "clouds\t0\n",
    "transformed\t2\n",
    "into\t0\n",
    "a\t0\n",
    "me\t0\n",
    "##sm\t0\n",
    "##eri\t0\n",
    "##zing\t7\n",
    "canvas\t8\n",
    "of\t0\n",
    "vibrant\t7\n",
    "orange\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "pink\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "and\t0\n",
    "purple\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "painting\t9\n",
    "a\t1\n",
    "breath\t5\n",
    "##taking\t10\n",
    "masterpiece\t9\n",
    "of\t0\n",
    "nature\t1\n",
    "'\t0\n",
    "s\t0\n",
    "artistic\t8\n",
    "prowess\t5\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>[CLS]\t1\n",
    "casting\t4\n",
    "warm\t3\n",
    "golden\t2\n",
    "hue\t2\n",
    "vast\t5\n",
    "expanse\t4\n",
    "transformed\t2\n",
    "##zing\t7\n",
    "canvas\t8\n",
    "vibrant\t7\n",
    "painting\t9\n",
    "a\t1\n",
    "breath\t5\n",
    "##taking\t10\n",
    "masterpiece\t9\n",
    "nature\t1\n",
    "artistic\t8\n",
    "prowess\t5\n",
    "<end>\n",
    "Explanation of Factor: The main thing this cluster of neurons does is find words that describe a natural and artistic scene.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 6:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "as\t0\n",
    "the\t0\n",
    "sun\t0\n",
    "slowly\t0\n",
    "descended\t0\n",
    "below\t0\n",
    "the\t0\n",
    "horizon\t0\n",
    ",\t0\n",
    "casting\t0\n",
    "a\t0\n",
    "warm\t0\n",
    "golden\t0\n",
    "hue\t0\n",
    "across\t0\n",
    "the\t0\n",
    "vast\t0\n",
    "expanse\t0\n",
    "of\t0\n",
    "the\t0\n",
    "sky\t0\n",
    ",\t0\n",
    "the\t0\n",
    "clouds\t0\n",
    "transformed\t0\n",
    "into\t0\n",
    "a\t0\n",
    "me\t0\n",
    "##sm\t0\n",
    "##eri\t0\n",
    "##zing\t0\n",
    "canvas\t0\n",
    "of\t0\n",
    "vibrant\t0\n",
    "orange\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "pink\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "and\t0\n",
    "purple\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "painting\t0\n",
    "a\t0\n",
    "breath\t0\n",
    "##taking\t0\n",
    "masterpiece\t0\n",
    "of\t1\n",
    "nature\t1\n",
    "'\t10\n",
    "s\t9\n",
    "artistic\t1\n",
    "prowess\t1\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>of\t1\n",
    "nature\t1\n",
    "'\t10\n",
    "s\t9\n",
    "artistic\t1\n",
    "prowess\t1\n",
    "<end>\n",
    "Explanation of Factor: The main thing this cluster of neurons does is find words related to nature, beauty, and artistic prowess.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 7:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "as\t0\n",
    "the\t0\n",
    "sun\t0\n",
    "slowly\t0\n",
    "descended\t0\n",
    "below\t0\n",
    "the\t0\n",
    "horizon\t0\n",
    ",\t0\n",
    "casting\t0\n",
    "a\t0\n",
    "warm\t0\n",
    "golden\t0\n",
    "hue\t0\n",
    "across\t1\n",
    "the\t0\n",
    "vast\t0\n",
    "expanse\t0\n",
    "of\t8\n",
    "the\t0\n",
    "sky\t0\n",
    ",\t0\n",
    "the\t0\n",
    "clouds\t0\n",
    "transformed\t0\n",
    "into\t0\n",
    "a\t0\n",
    "me\t0\n",
    "##sm\t0\n",
    "##eri\t0\n",
    "##zing\t0\n",
    "canvas\t0\n",
    "of\t10\n",
    "vibrant\t0\n",
    "orange\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "pink\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "and\t0\n",
    "purple\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "painting\t0\n",
    "a\t0\n",
    "breath\t0\n",
    "##taking\t0\n",
    "masterpiece\t0\n",
    "of\t9\n",
    "nature\t0\n",
    "'\t0\n",
    "s\t0\n",
    "artistic\t0\n",
    "prowess\t0\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>across\t1\n",
    "of\t8\n",
    "of\t10\n",
    "of\t9\n",
    "<end>\n",
    "Explanation of Factor: The main thing this cluster of neurons does is find the word \"of\".\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 8:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "as\t0\n",
    "the\t0\n",
    "sun\t0\n",
    "slowly\t5\n",
    "descended\t10\n",
    "below\t7\n",
    "the\t0\n",
    "horizon\t0\n",
    ",\t0\n",
    "casting\t4\n",
    "a\t0\n",
    "warm\t1\n",
    "golden\t1\n",
    "hue\t1\n",
    "across\t7\n",
    "the\t0\n",
    "vast\t1\n",
    "expanse\t2\n",
    "of\t1\n",
    "the\t0\n",
    "sky\t0\n",
    ",\t0\n",
    "the\t0\n",
    "clouds\t0\n",
    "transformed\t7\n",
    "into\t3\n",
    "a\t0\n",
    "me\t0\n",
    "##sm\t0\n",
    "##eri\t0\n",
    "##zing\t0\n",
    "canvas\t0\n",
    "of\t0\n",
    "vibrant\t0\n",
    "orange\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "pink\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "and\t0\n",
    "purple\t0\n",
    "##s\t0\n",
    ",\t0\n",
    "painting\t0\n",
    "a\t0\n",
    "breath\t0\n",
    "##taking\t0\n",
    "masterpiece\t0\n",
    "of\t0\n",
    "nature\t0\n",
    "'\t0\n",
    "s\t0\n",
    "artistic\t0\n",
    "prowess\t0\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>slowly\t5\n",
    "descended\t10\n",
    "below\t7\n",
    "casting\t4\n",
    "warm\t1\n",
    "golden\t1\n",
    "hue\t1\n",
    "across\t7\n",
    "vast\t1\n",
    "expanse\t2\n",
    "of\t1\n",
    "transformed\t7\n",
    "into\t3\n",
    "<end>\n",
    "Explanation of Factor: The main thing this cluster of neurons does is find words related to a scene of sunset and transformation.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 10:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "as\t0\n",
    "the\t0\n",
    "sun\t0\n",
    "slowly\t0\n",
    "descended\t0\n",
    "below\t0\n",
    "the\t0\n",
    "horizon\t0\n",
    ",\t0\n",
    "casting\t0\n",
    "a\t0\n",
    "warm\t0\n",
    "golden\t0\n",
    "hue\t0\n",
    "across\t0\n",
    "the\t0\n",
    "vast\t0\n",
    "expanse\t0\n",
    "of\t0\n",
    "the\t0\n",
    "sky\t0\n",
    ",\t0\n",
    "the\t0\n",
    "clouds\t0\n",
    "transformed\t0\n",
    "into\t0\n",
    "a\t0\n",
    "me\t0\n",
    "##sm\t0\n",
    "##eri\t0\n",
    "##zing\t0\n",
    "canvas\t0\n",
    "of\t0\n",
    "vibrant\t0\n",
    "orange\t0\n",
    "##s\t9\n",
    ",\t0\n",
    "pink\t0\n",
    "##s\t10\n",
    ",\t0\n",
    "and\t0\n",
    "purple\t0\n",
    "##s\t9\n",
    ",\t0\n",
    "painting\t0\n",
    "a\t0\n",
    "breath\t0\n",
    "##taking\t0\n",
    "masterpiece\t0\n",
    "of\t0\n",
    "nature\t0\n",
    "'\t0\n",
    "s\t0\n",
    "artistic\t0\n",
    "prowess\t0\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>##s\t9\n",
    "##s\t10\n",
    "##s\t9\n",
    "<end>\n",
    "Explanation of Factor: The main thing this cluster of neurons does is find 's', when it indicates plural.\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "Factor 13:\n",
    "Activations\n",
    "<start>\n",
    "\n",
    "[CLS]\t0\n",
    "as\t0\n",
    "the\t0\n",
    "sun\t0\n",
    "slowly\t0\n",
    "descended\t0\n",
    "below\t0\n",
    "the\t0\n",
    "horizon\t0\n",
    ",\t0\n",
    "casting\t0\n",
    "a\t0\n",
    "warm\t2\n",
    "golden\t5\n",
    "hue\t3\n",
    "across\t0\n",
    "the\t0\n",
    "vast\t0\n",
    "expanse\t0\n",
    "of\t0\n",
    "the\t0\n",
    "sky\t0\n",
    ",\t0\n",
    "the\t0\n",
    "clouds\t0\n",
    "transformed\t0\n",
    "into\t0\n",
    "a\t0\n",
    "me\t0\n",
    "##sm\t0\n",
    "##eri\t0\n",
    "##zing\t0\n",
    "canvas\t0\n",
    "of\t0\n",
    "vibrant\t3\n",
    "orange\t10\n",
    "##s\t0\n",
    ",\t0\n",
    "pink\t9\n",
    "##s\t0\n",
    ",\t0\n",
    "and\t0\n",
    "purple\t9\n",
    "##s\t0\n",
    ",\t0\n",
    "painting\t0\n",
    "a\t0\n",
    "breath\t0\n",
    "##taking\t0\n",
    "masterpiece\t0\n",
    "of\t0\n",
    "nature\t0\n",
    "'\t0\n",
    "s\t0\n",
    "artistic\t0\n",
    "prowess\t0\n",
    ".\t0\n",
    "[SEP]\t0\n",
    "<end>\n",
    "same_string but with all zeros filtered out:\n",
    "\n",
    "<start>warm\t2\n",
    "golden\t5\n",
    "hue\t3\n",
    "vibrant\t3\n",
    "orange\t10\n",
    "pink\t9\n",
    "purple\t9\n",
    "<end>\n",
    "Explanation of Factor: The main thing this cluster of neurons does is find adjectives and colours related to the beauty of a scene. \n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "\n",
    ": The main thing this cluster of neurons does is find\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "\n",
    ": The main thing this cluster of neurons does is find\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "\n",
    ": The main thing this cluster of neurons does is find\n",
    "\"\"\"\n",
    "explanations.append(explanation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding the explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from https://github.com/openai/openai-cookbook/blob/2a2753e8d0566fbf21a8270ce6afaf761d7cdee5/examples/Embedding_Wikipedia_articles_for_search.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import openai  # for generating embeddings\n",
    "import pandas as pd  # for DataFrames to store article sections and embeddings\n",
    "import tiktoken  # for counting tokens\n",
    "# remove api_key before publishing\n",
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_MODEL = \"text-davinci-003\"  # only matters insofar as it selects which tokenizer to use\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"  # OpenAI's best embeddings as of Apr 2023\n",
    "BATCH_SIZE = 1000  # you can submit up to 2048 embedding inputs per request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 to 999\n"
     ]
    }
   ],
   "source": [
    "# Calculate embedding model\n",
    "embeddings = []\n",
    "for batch_start in range(0, len(explanations), BATCH_SIZE):\n",
    "    batch_end = batch_start + BATCH_SIZE\n",
    "    batch = explanations[batch_start:batch_end]\n",
    "    print(f\"Batch {batch_start} to {batch_end-1}\")\n",
    "    response = openai.Embedding.create(model=EMBEDDING_MODEL, input=batch)\n",
    "    for i, be in enumerate(response[\"data\"]):\n",
    "        assert i == be[\"index\"]  # double check embeddings are in same order as input\n",
    "    batch_embeddings = [e[\"embedding\"] for e in response[\"data\"]]\n",
    "    embeddings.extend(batch_embeddings)\n",
    "\n",
    "df = pd.DataFrame({\"text\": explanations, \"embedding\": embeddings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to make sure they do not contain more tokens than X first :')\n",
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens(explanations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elements in explanations list = 31\n",
      "explanations with less than 500 tokens = 30\n"
     ]
    }
   ],
   "source": [
    "# should make sure that at least 1 explanation can fit into prompt\n",
    "# create new list only containing explanations under token_limit_explanations\n",
    "token_limit_explanations = 500\n",
    "initial_elements_in_list = len(explanations)\n",
    "explanations = [x for x in explanations if num_tokens(x)<token_limit_explanations]\n",
    "print(f'elements in explanations list = {initial_elements_in_list}')\n",
    "print(f'explanations with less than {token_limit_explanations} tokens = {len(explanations)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nActivations:'Factor 1:\\nActivations\\n&lt;start&gt;...</td>\n",
       "      <td>[0.0006081134779378772, -0.007446360774338245,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nActivations: 'Factor 2:\\nActivations\\n&lt;start...</td>\n",
       "      <td>[-0.0020358962938189507, -0.003475616686046123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nActivations: 'Factor 3:\\nActivations\\n&lt;start...</td>\n",
       "      <td>[-0.004744586534798145, -0.003105047857388854,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nActivations: 'Factor 1:\\nActivations\\n&lt;start...</td>\n",
       "      <td>[-0.0018072226084768772, -0.006984452251344919...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nActivations: 'Factor 2:\\nActivations\\n&lt;start...</td>\n",
       "      <td>[-0.005746796261519194, -0.004403814673423767,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  \\nActivations:'Factor 1:\\nActivations\\n<start>...   \n",
       "1  \\nActivations: 'Factor 2:\\nActivations\\n<start...   \n",
       "2  \\nActivations: 'Factor 3:\\nActivations\\n<start...   \n",
       "3  \\nActivations: 'Factor 1:\\nActivations\\n<start...   \n",
       "4  \\nActivations: 'Factor 2:\\nActivations\\n<start...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.0006081134779378772, -0.007446360774338245,...  \n",
       "1  [-0.0020358962938189507, -0.003475616686046123...  \n",
       "2  [-0.004744586534798145, -0.003105047857388854,...  \n",
       "3  [-0.0018072226084768772, -0.006984452251344919...  \n",
       "4  [-0.005746796261519194, -0.004403814673423767,...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save explanations and embeddings\n",
    "SAVE_PATH = \"C:/Users/erikm/dropbox/openai_like_explanations.csv\"\n",
    "\n",
    "df.to_csv(SAVE_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nActivations:'Factor 1:\\nActivations\\n&lt;start&gt;...</td>\n",
       "      <td>[0.0006081134779378772, -0.007446360774338245,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nActivations: 'Factor 2:\\nActivations\\n&lt;start...</td>\n",
       "      <td>[-0.0020358962938189507, -0.003475616686046123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nActivations: 'Factor 3:\\nActivations\\n&lt;start...</td>\n",
       "      <td>[-0.004744586534798145, -0.003105047857388854,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nActivations: 'Factor 1:\\nActivations\\n&lt;start...</td>\n",
       "      <td>[-0.0018072226084768772, -0.006984452251344919...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nActivations: 'Factor 2:\\nActivations\\n&lt;start...</td>\n",
       "      <td>[-0.005746796261519194, -0.004403814673423767,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  \\nActivations:'Factor 1:\\nActivations\\n<start>...   \n",
       "1  \\nActivations: 'Factor 2:\\nActivations\\n<start...   \n",
       "2  \\nActivations: 'Factor 3:\\nActivations\\n<start...   \n",
       "3  \\nActivations: 'Factor 1:\\nActivations\\n<start...   \n",
       "4  \\nActivations: 'Factor 2:\\nActivations\\n<start...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.0006081134779378772, -0.007446360774338245,...  \n",
       "1  [-0.0020358962938189507, -0.003475616686046123...  \n",
       "2  [-0.004744586534798145, -0.003105047857388854,...  \n",
       "3  [-0.0018072226084768772, -0.006984452251344919...  \n",
       "4  [-0.005746796261519194, -0.004403814673423767,...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_df = pd.read_csv(SAVE_PATH)\n",
    "csv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pkl_savepath = \"C:/Users/erikm/dropbox/openai_like_explanations.pkl\"\n",
    "with open(pkl_savepath, 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pkl_savepath = \"C:/Users/erikm/dropbox/openai_like_explanations.pkl\"\n",
    "with open(pkl_savepath, 'rb') as f:\n",
    "    pickle_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nActivations:['Factor 1:\\nActivations\\n&lt;start...</td>\n",
       "      <td>[0.0018603604985401034, -0.007592866662889719,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nActivations: 'Factor 2:\\nActivations\\n&lt;start...</td>\n",
       "      <td>[-0.0020244817715138197, -0.003155129263177514...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nActivations: 'Factor 3:\\nActivations\\n&lt;start...</td>\n",
       "      <td>[-0.004702421370893717, -0.0031300606206059456...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nActivations: 'Factor 1:\\nActivations\\n&lt;start...</td>\n",
       "      <td>[-0.001777758589014411, -0.0070751020684838295...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nActivations: 'Factor 2:\\nActivations\\n&lt;start...</td>\n",
       "      <td>[-0.005726929288357496, -0.0043916162103414536...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  \\nActivations:['Factor 1:\\nActivations\\n<start...   \n",
       "1  \\nActivations: 'Factor 2:\\nActivations\\n<start...   \n",
       "2  \\nActivations: 'Factor 3:\\nActivations\\n<start...   \n",
       "3  \\nActivations: 'Factor 1:\\nActivations\\n<start...   \n",
       "4  \\nActivations: 'Factor 2:\\nActivations\\n<start...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.0018603604985401034, -0.007592866662889719,...  \n",
       "1  [-0.0020244817715138197, -0.003155129263177514...  \n",
       "2  [-0.004702421370893717, -0.0031300606206059456...  \n",
       "3  [-0.001777758589014411, -0.0070751020684838295...  \n",
       "4  [-0.005726929288357496, -0.0043916162103414536...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search in embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search function\n",
    "# # Adapted from https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb\n",
    "import ast  # for converting embeddings saved as strings back to arrays\n",
    "import openai  # for calling the OpenAI API\n",
    "import pandas as pd  # for storing text and embeddings data\n",
    "import tiktoken  # for counting tokens\n",
    "from scipy import spatial  # for calculating vector similarities for search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings_ranked_by_relatedness(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
    "    top_n: int = 100\n",
    ") -> tuple[list[str], list[float]]:\n",
    "    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n",
    "    query_embedding_response = openai.Embedding.create(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        input=query,\n",
    "    )\n",
    "    query_embedding = query_embedding_response[\"data\"][0][\"embedding\"]\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "    return strings[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pkl_savepath = \"C:/Users/erikm/dropbox/explanations.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings_ranked_by_relatedness(\n",
    "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
    "    top_n: int = 10\n",
    "): \n",
    "    pkl_savepath = \"C:/Users/erikm/dropbox/explanations.pkl\"\n",
    "    with open(pkl_savepath, 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "    query = \"test example\"\n",
    "    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n",
    "    query_embedding_response = openai.Embedding.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=query,\n",
    "    )\n",
    "    query_embedding = query_embedding_response[\"data\"][0][\"embedding\"]\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "    return strings[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedding_searcher import Searcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'This is the activations:'\n",
    "#test_prompt = add_examples_to_prompt(input_text, explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = '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'\n",
    "searcher = Searcher(input_text, openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"\\nActivations:['Factor 1:\\nActivations\\n<start>\\n[CLS]\\t0\\n1\\t0\\n,\\t2\\n2\\t0\\n,\\t2\\n3\\t0\\n,\\t2\\n4\\t0\\n,\\t2\\n5\\t0\\n,\\t2\\n6\\t0\\n,\\t2\\n7\\t0\\n,\\t2\\n8\\t0\\n,\\t2\\n9\\t0\\n,\\t2\\n10\\t0\\n,\\t2\\n11\\t0\\n,\\t2\\n12\\t0\\n,\\t2\\n13\\t0\\n,\\t2\\n14\\t0\\n,\\t2\\n15\\t0\\n,\\t2\\n16\\t0\\n,\\t2\\n17\\t0\\n,\\t2\\n18\\t0\\n[SEP]\\t0\\n<end>\\nsame_string but with all zeros filtered out:\\n<start>,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n<end>\\n',\\nExplanation of Factor 1: the main thing this factor does is find commas\\n\",\n",
       " \"\\nActivations: 'Factor 3:\\nActivations\\n<start>\\n[CLS]\\t0\\n1\\t1\\n,\\t0\\n2\\t2\\n,\\t0\\n3\\t2\\n,\\t0\\n4\\t2\\n,\\t0\\n5\\t3\\n,\\t0\\n6\\t2\\n,\\t0\\n7\\t3\\n,\\t0\\n8\\t3\\n,\\t0\\n9\\t3\\n,\\t0\\n10\\t3\\n,\\t0\\n11\\t3\\n,\\t0\\n12\\t3\\n,\\t0\\n13\\t3\\n,\\t0\\n14\\t3\\n,\\t0\\n15\\t2\\n,\\t0\\n16\\t2\\n,\\t0\\n17\\t2\\n,\\t0\\n18\\t2\\n[SEP]\\t0\\n<end>\\nsame_string but with all zeros filtered out:\\n<start>1\\t1\\n2\\t2\\n3\\t2\\n4\\t2\\n5\\t3\\n6\\t2\\n7\\t3\\n8\\t3\\n9\\t3\\n10\\t3\\n11\\t3\\n12\\t3\\n13\\t3\\n14\\t3\\n15\\t2\\n16\\t2\\n17\\t2\\n18\\t2\\n<end>\\n']\\nExplanation of Factor 3: the main thing this factor does is find incrementing numbers\\n\",\n",
       " \"\\nActivations: 'Factor 2:\\nActivations\\n<start>\\n[CLS]\\t0\\n1\\t0\\n,\\t0\\n2\\t0\\n,\\t0\\n3\\t0\\n,\\t0\\n4\\t0\\n,\\t0\\n5\\t0\\n,\\t0\\n6\\t0\\n,\\t0\\n7\\t0\\n,\\t0\\n8\\t0\\n,\\t0\\n9\\t0\\n,\\t0\\n10\\t0\\n,\\t0\\n11\\t0\\n,\\t0\\n12\\t0\\n,\\t0\\n13\\t0\\n,\\t0\\n14\\t0\\n,\\t0\\n15\\t0\\n,\\t0\\n16\\t0\\n,\\t0\\n17\\t0\\n,\\t0\\n18\\t0\\n[SEP]\\t10\\n<end>\\nsame_string but with all zeros filtered out:\\n<start>[SEP]\\t10\\n<end>\\n',\\nExplanation of Factor 2: the main thing this factor does is find the [SEP] token, denoting the end of the sentence.\\n\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher.get_examples_ranked_by_relatedness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is the activations:\\nActivations: 'Factor 2:\\nActivations\\n<start>\\n[CLS]\\t0\\n1\\t0\\n,\\t0\\n2\\t0\\n,\\t0\\n3\\t0\\n,\\t0\\n4\\t0\\n,\\t0\\n5\\t0\\n,\\t0\\n6\\t0\\n,\\t0\\n7\\t0\\n,\\t0\\n8\\t0\\n,\\t0\\n9\\t0\\n,\\t0\\n10\\t0\\n,\\t0\\n11\\t0\\n,\\t0\\n12\\t0\\n,\\t0\\n13\\t0\\n,\\t0\\n14\\t0\\n,\\t0\\n15\\t0\\n,\\t0\\n16\\t0\\n,\\t0\\n17\\t0\\n,\\t0\\n18\\t0\\n[SEP]\\t10\\n<end>\\nsame_string but with all zeros filtered out:\\n<start>[SEP]\\t10\\n<end>\\n',\\nExplanation of Factor 2: the main thing this factor does is find the [SEP] token, denoting the end of the sentence.\\n\\nActivations:['Factor 1:\\nActivations\\n<start>\\n[CLS]\\t0\\n1\\t0\\n,\\t2\\n2\\t0\\n,\\t2\\n3\\t0\\n,\\t2\\n4\\t0\\n,\\t2\\n5\\t0\\n,\\t2\\n6\\t0\\n,\\t2\\n7\\t0\\n,\\t2\\n8\\t0\\n,\\t2\\n9\\t0\\n,\\t2\\n10\\t0\\n,\\t2\\n11\\t0\\n,\\t2\\n12\\t0\\n,\\t2\\n13\\t0\\n,\\t2\\n14\\t0\\n,\\t2\\n15\\t0\\n,\\t2\\n16\\t0\\n,\\t2\\n17\\t0\\n,\\t2\\n18\\t0\\n[SEP]\\t0\\n<end>\\nsame_string but with all zeros filtered out:\\n<start>,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n,\\t2\\n<end>\\n',\\nExplanation of Factor 1: the main thing this factor does is find commas\\n\\nActivations: 'Factor 3:\\nActivations\\n<start>\\n[CLS]\\t0\\n1\\t1\\n,\\t0\\n2\\t2\\n,\\t0\\n3\\t2\\n,\\t0\\n4\\t2\\n,\\t0\\n5\\t3\\n,\\t0\\n6\\t2\\n,\\t0\\n7\\t3\\n,\\t0\\n8\\t3\\n,\\t0\\n9\\t3\\n,\\t0\\n10\\t3\\n,\\t0\\n11\\t3\\n,\\t0\\n12\\t3\\n,\\t0\\n13\\t3\\n,\\t0\\n14\\t3\\n,\\t0\\n15\\t2\\n,\\t0\\n16\\t2\\n,\\t0\\n17\\t2\\n,\\t0\\n18\\t2\\n[SEP]\\t0\\n<end>\\nsame_string but with all zeros filtered out:\\n<start>1\\t1\\n2\\t2\\n3\\t2\\n4\\t2\\n5\\t3\\n6\\t2\\n7\\t3\\n8\\t3\\n9\\t3\\n10\\t3\\n11\\t3\\n12\\t3\\n13\\t3\\n14\\t3\\n15\\t2\\n16\\t2\\n17\\t2\\n18\\t2\\n<end>\\n']\\nExplanation of Factor 3: the main thing this factor does is find incrementing numbers\\nThe main thing this cluster does is find\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = searcher.add_examples_to_prompt()\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "944"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens(test_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
